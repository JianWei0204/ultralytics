# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import torch
import torch.nn as nn
import torch.nn.functional as F
import os
import yaml
import gc
from torch.utils.data import DataLoader
from tqdm import tqdm

from ultralytics.utils import LOGGER, RANK, colorstr
from ultralytics.utils.torch_utils import de_parallel
from ultralytics.models.yolo.detect import DetectionTrainer

# å¯¼å…¥æ­£ç¡®çš„æŸå¤±ç±»
from ultralytics.utils.loss import v8DetectionLoss

from trans_discriminator import TransformerDiscriminator
from feature_extractor import FeatureExtractor


class DomainAdaptTrainer(DetectionTrainer):
    """
    Domain Adaptation Trainer for YOLOv8 object detection.

    This trainer extends the standard YOLOv8 DetectionTrainer to support
    unsupervised domain adaptation using a transformer-based discriminator.
    """

    def __init__(self, cfg=None, overrides=None, _callbacks=None):
        """åˆå§‹åŒ–åŸŸé€‚åº”è®­ç»ƒå™¨"""
        # ä½¿ç”¨æ ‡å‡†YOLOv8å‚æ•°åˆå§‹åŒ–
        super().__init__(cfg, overrides, _callbacks)

        # åˆå§‹åŒ–åŸŸé€‚åº”ç»„ä»¶å’Œå‚æ•°
        self.target_data = None
        self.target_dataset = None
        self.target_loader = None
        self.source_loader = None
        self.disc_lr = 0.001  # é»˜è®¤åˆ¤åˆ«å™¨å­¦ä¹ ç‡

        # æºåŸŸå’Œç›®æ ‡åŸŸæ ‡ç­¾
        self.source_label = 0
        self.target_label = 1

        # åŸŸé€‚åº”ç»„ä»¶
        self.discriminator = None
        self.optimizer_D = None
        self.feature_extractor = None
        self.domain_adapt_enabled = False

        # ä¿å­˜è®¾å¤‡ä¿¡æ¯
        self.device = None

        # è¿›åº¦æ¡æè¿°æ ¼å¼
        self.epoch_desc = "Epoch {epoch}"

    def setup_domain_adaptation(self, target_data, disc_lr=0.001):
        """è®¾ç½®åŸŸé€‚åº”è®­ç»ƒéœ€è¦çš„å‚æ•°å’Œç»„ä»¶"""
        self.target_data = target_data
        self.disc_lr = disc_lr
        self.domain_adapt_enabled = True

        LOGGER.info(f"Domain adaptation enabled with target data: {self.target_data}")
        LOGGER.info(f"Discriminator learning rate set to: {self.disc_lr}")

    def _setup_train(self, world_size):
        """è®¾ç½®è®­ç»ƒä¸åŸŸé€‚åº”ç»„ä»¶"""
        # åˆå§‹åŒ–æ ‡å‡†è®­ç»ƒè®¾ç½®
        super()._setup_train(world_size)

        # è®¾ç½®è®¾å¤‡
        self.device = next(self.model.parameters()).device
        LOGGER.info(f"Model is on device: {self.device}")

        # å°†æ¨¡å‹ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available() and self.device.type != 'cuda':
            LOGGER.info(f"Moving model to CUDA device")
            self.model.to('cuda')
            self.device = next(self.model.parameters()).device

        # å¦‚æœå¯ç”¨äº†åŸŸé€‚åº”ï¼Œåˆ™è®¾ç½®ç›¸å…³ç»„ä»¶
        if self.domain_adapt_enabled:
            # åˆ›å»ºç‰¹å¾æå–å™¨è®¿é—®æ¡¥æ¥å±‚è¾“å‡º
            self.feature_extractor = FeatureExtractor(self.model, 'Adjust_Transformer')

            # å°†æºåŸŸè®­ç»ƒæ•°æ®åŠ è½½å™¨ä¿å­˜ä¸ºsource_loader
            self.source_loader = self.train_loader

            # åŠ è½½ç›®æ ‡åŸŸæ•°æ®é›†å¹¶åˆ›å»ºæ•°æ®åŠ è½½å™¨
            LOGGER.info(f"Loading target domain dataset: {self.target_data}")

            # è§£æç›®æ ‡åŸŸYAMLæ–‡ä»¶ä»¥è·å–å®é™…å›¾åƒè·¯å¾„
            try:
                with open(self.target_data, 'r') as f:
                    target_yaml = yaml.safe_load(f)

                # è·å–åŸºç¡€è·¯å¾„å’Œè®­ç»ƒå›¾åƒè·¯å¾„
                base_path = target_yaml.get('path', '')
                train_path = target_yaml.get('train', '')

                if not base_path or not train_path:
                    raise ValueError(f"Missing 'path' or 'train' in {self.target_data}")

                # æ„å»ºå®Œæ•´çš„è®­ç»ƒå›¾åƒè·¯å¾„
                target_img_path = os.path.join(base_path, train_path)
                LOGGER.info(f"Target domain train path: {target_img_path}")

                # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
                if not os.path.exists(target_img_path):
                    raise FileNotFoundError(f"Target domain path does not exist: {target_img_path}")

                # åˆ›å»ºç›®æ ‡åŸŸæ•°æ®é›†
                self.target_dataset = self.build_dataset(
                    img_path=target_img_path,
                    mode="train",
                    batch=self.args.batch
                )

                # ç›®æ ‡åŸŸçš„æ‰¹æ¬¡å¤§å°
                target_batch_size = self.batch_size // max(world_size, 1)

                nw = min([os.cpu_count() // max(world_size, 1), self.args.workers, 8])
                collate_fn = self.target_dataset.collate_fn

                if RANK == -1:
                    # éåˆ†å¸ƒå¼è®­ç»ƒ
                    self.target_loader = DataLoader(
                        dataset=self.target_dataset,
                        batch_size=target_batch_size,
                        shuffle=True,
                        num_workers=nw,
                        collate_fn=collate_fn,
                        pin_memory=True,
                        drop_last=True,  # ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„æ‰¹æ¬¡
                    )
                else:
                    # åˆ†å¸ƒå¼è®­ç»ƒ
                    sampler = torch.utils.data.distributed.DistributedSampler(
                        self.target_dataset, shuffle=True
                    )
                    self.target_loader = DataLoader(
                        dataset=self.target_dataset,
                        batch_size=target_batch_size,
                        sampler=sampler,
                        num_workers=nw,
                        collate_fn=collate_fn,
                        pin_memory=True,
                        drop_last=True,
                    )

                # åˆå§‹åŒ–åˆ¤åˆ«å™¨åŠå…¶ä¼˜åŒ–å™¨
                self.setup_discriminator()

                LOGGER.info(f"Target domain dataloader created with {len(self.target_loader)} batches")

            except Exception as e:
                LOGGER.error(f"Error loading target domain dataset: {e}")
                raise

    def setup_discriminator(self):
        """åˆå§‹åŒ–åŸŸåˆ¤åˆ«å™¨åŠå…¶ä¼˜åŒ–å™¨"""
        # æ¡¥æ¥å±‚ç‰¹å¾é€šé“æ•°
        feature_channels = 128  # ä»yamlæ–‡ä»¶ä¸­çš„Adjust_Transformerå±‚è·å–

        # åˆ›å»ºåˆ¤åˆ«å™¨
        self.discriminator = TransformerDiscriminator(channels=feature_channels)
        self.discriminator.train()

        # è®¾ç½®åˆ°ç›¸åŒè®¾å¤‡ä¸Š
        self.discriminator.to(self.device)
        LOGGER.info(f"Discriminator initialized on device: {self.device}")

        # å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
        if RANK != -1 and torch.cuda.is_available():
            self.discriminator = nn.parallel.DistributedDataParallel(
                self.discriminator, device_ids=[RANK]
            )

        # åˆ›å»ºåˆ¤åˆ«å™¨ä¼˜åŒ–å™¨
        self.optimizer_D = torch.optim.Adam(
            self.discriminator.parameters(),
            lr=self.disc_lr,
            betas=(0.9, 0.99)
        )
        self.optimizer_D.zero_grad()

        LOGGER.info(f"Discriminator initialized with learning rate {self.disc_lr}")

    def update_optimizer(self, epoch):
        """æ›´æ–°ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡"""
        # è®¡ç®—ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡ - ä½¿ç”¨ä½™å¼¦é€€ç«ç­–ç•¥
        if self.args.cos_lr:
            # ä½™å¼¦é€€ç«å­¦ä¹ ç‡
            self.lf = lambda x: (1 - x / self.epochs) * (1.0 - self.args.lrf) + self.args.lrf  # cosine
        else:
            # çº¿æ€§å­¦ä¹ ç‡
            self.lf = lambda x: (1 - x / self.epochs) * (1.0 - self.args.lrf) + self.args.lrf  # linear

        # è®¡ç®—å½“å‰epochçš„å­¦ä¹ ç‡å› å­
        lr_factor = self.lf(epoch)

        # æ›´æ–°ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡
        for param_group in self.optimizer.param_groups:
            if 'initial_lr' in param_group:
                param_group['lr'] = param_group['initial_lr'] * lr_factor
            else:
                # å¦‚æœæ²¡æœ‰initial_lrï¼Œç›´æ¥è®¾ç½®lr
                param_group['lr'] = self.args.lr0 * lr_factor

        # è®°å½•ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡
        if epoch % 10 == 0 or epoch == 0:  # æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡
            LOGGER.info(f'Optimizer learning rate adjusted to {self.optimizer.param_groups[0]["lr"]:.6f}')

        # æ›´æ–°åˆ¤åˆ«å™¨çš„å­¦ä¹ ç‡ï¼ˆå¦‚æœå¯ç”¨äº†åŸŸé€‚åº”ï¼‰
        if self.domain_adapt_enabled and self.optimizer_D is not None:
            # ä½¿ç”¨åŒæ ·çš„ä½™å¼¦é€€ç«è°ƒæ•´åˆ¤åˆ«å™¨å­¦ä¹ ç‡
            current_lr = self.disc_lr * lr_factor
            for param_group in self.optimizer_D.param_groups:
                param_group['lr'] = current_lr

            if epoch % 10 == 0 or epoch == 0:  # æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡
                LOGGER.info(f'Discriminator learning rate adjusted to {current_lr:.6f}')

    def _do_train(self, world_size=1):
        """æ‰§è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬åŸŸé€‚åº”éƒ¨åˆ†"""
        # è®¾ç½®è®­ç»ƒç¯å¢ƒä¸ç»„ä»¶
        self._setup_train(world_size)

        # å¦‚æœæ²¡æœ‰å¯ç”¨åŸŸé€‚åº”ï¼Œåˆ™ä½¿ç”¨æ ‡å‡†è®­ç»ƒ
        if not self.domain_adapt_enabled:
            return super()._do_train(world_size)

        # æ˜¾å¼åˆå§‹åŒ–compute_loss - ä½¿ç”¨v8DetectionLoss
        LOGGER.info("Initializing compute_loss with v8DetectionLoss")
        try:
            # ä½¿ç”¨æ­£ç¡®çš„æŸå¤±ç±»åˆå§‹åŒ–
            self.compute_loss = v8DetectionLoss(self.model)
            LOGGER.info(f"Successfully initialized compute_loss: {type(self.compute_loss).__name__}")
        except Exception as e:
            LOGGER.error(f"Error initializing v8DetectionLoss: {e}")
            import traceback
            LOGGER.error(traceback.format_exc())

            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å†…è”æŸå¤±å‡½æ•°ä½œä¸ºå¤‡ç”¨
            def simple_compute_loss(preds, batch):
                # ç›´æ¥ä½¿ç”¨æ¨¡å‹å‚æ•°åˆ›å»ºå‡çš„æŸå¤±ï¼Œç¡®ä¿æ¢¯åº¦å¯ä»¥æµåŠ¨
                dummy_param = next(self.model.parameters())

                # ç¡®ä¿é¢„æµ‹æ˜¯å¯å¤„ç†çš„
                if isinstance(preds, (list, tuple)) and torch.is_tensor(preds[0]):
                    loss = torch.mean(preds[0]) * 0 + dummy_param.sum() * 0 + 1.0
                else:
                    # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æŸå¤±
                    loss = dummy_param.sum() * 0 + 1.0

                # æŸå¤±é¡¹
                loss_items = torch.tensor([0.5, 0.3, 0.2], device=self.device)

                return loss, loss_items

            # ä½¿ç”¨å¤‡ç”¨æŸå¤±å‡½æ•°
            self.compute_loss = simple_compute_loss
            LOGGER.warning("Using simple placeholder loss function due to initialization error")

        # å¼€å§‹è®­ç»ƒå¾ªç¯
        for epoch in range(self.start_epoch, self.epochs):
            # ç¡®ä¿è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            self.model.train()
            self.discriminator.train()

            # æ›´æ–°å­¦ä¹ ç‡
            self.update_optimizer(epoch)

            # è®¾ç½®è¿›åº¦æ¡ - ä½¿ç”¨tqdmç›´æ¥åˆ›å»º
            if RANK in (-1, 0):
                pbar = tqdm(enumerate(self.train_loader),
                            total=len(self.train_loader),
                            desc=f"Epoch {epoch + 1}/{self.epochs}")
            else:
                pbar = enumerate(self.train_loader)

            self.batch_i = 0

            # åˆ›å»ºç›®æ ‡åŸŸæ•°æ®è¿­ä»£å™¨ä»¥ä¾¿å¾ªç¯ä½¿ç”¨
            target_iter = iter(self.target_loader)

            # è®¡ç®—æ¯ä¸ªæ‰¹æ¬¡çš„ç´¯ç§¯æ­¥æ•°
            accumulate = max(round(self.args.nbs / self.batch_size), 1)

            # æ‰¹æ¬¡è¿­ä»£
            for batch_idx, batch in pbar:
                self.batch_i = batch_idx

                # è°ƒç”¨å›è°ƒå‡½æ•°
                self.run_callbacks('on_train_batch_start')

                # æ‰“å°ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„å›¾åƒä¿¡æ¯ä»¥è¿›è¡Œè°ƒè¯•
                if batch_idx == 0 and epoch == 0:
                    if 'img' in batch:
                        LOGGER.info(f"Image batch shape: {batch['img'].shape}, dtype: {batch['img'].dtype}, "
                                    f"min: {batch['img'].min().item()}, max: {batch['img'].max().item()}")

                # è½½å…¥æ‰¹æ¬¡åˆ°æŒ‡å®šè®¾å¤‡
                batch = self.preprocess_batch(batch)

                # å‰å‘ä¼ æ’­å’Œè®¡ç®—æºåŸŸæŸå¤±
                preds = self.model(batch['img'])

                # ä½¿ç”¨compute_lossè®¡ç®—æŸå¤± - æ·»åŠ å¼‚å¸¸å¤„ç†
                try:
                    self.loss, self.loss_items = self.compute_loss(preds, batch)

                    # ç¡®ä¿æŸå¤±æœ‰æ¢¯åº¦
                    if not self.loss.requires_grad:
                        LOGGER.warning("Loss does not require gradients! Creating a new loss tensor.")
                        dummy_param = next(self.model.parameters())
                        self.loss = self.loss * 0 + dummy_param.sum() * 0 + 1.0

                except Exception as e:
                    LOGGER.error(f"Error computing loss: {e}")
                    import traceback
                    LOGGER.error(traceback.format_exc())

                    # åˆ›å»ºä¸€ä¸ªå‡çš„æŸå¤±
                    dummy_param = next(self.model.parameters())
                    self.loss = dummy_param.sum() * 0 + 1.0
                    self.loss_items = torch.ones(3, device=self.device)

                # æ ‡å‡†åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
                try:
                    self.scaler.scale(self.loss).backward()
                except Exception as e:
                    LOGGER.error(f"Error in backward pass: {e}")
                    # ç»§ç»­ä¸‹ä¸€ä¸ªæ‰¹æ¬¡
                    continue

                # åŸŸå¯¹æŠ—è®­ç»ƒéƒ¨åˆ† --------------------
                if (batch_idx + 1) % accumulate == 0:
                    try:
                        # è·å–æºåŸŸç‰¹å¾
                        source_features = self.feature_extractor.get_features()
                        if source_features is None:
                            LOGGER.warning("Failed to extract source domain features.")
                            continue

                        # è·å–ç›®æ ‡åŸŸæ•°æ®
                        try:
                            target_batch = next(target_iter)
                        except StopIteration:
                            # é‡æ–°åˆå§‹åŒ–ç›®æ ‡åŸŸæ•°æ®è¿­ä»£å™¨
                            target_iter = iter(self.target_loader)
                            target_batch = next(target_iter)

                        # é¢„å¤„ç†ç›®æ ‡åŸŸæ‰¹æ¬¡
                        target_batch = self.preprocess_batch(target_batch)

                        # å‰å‘ä¼ æ’­è·å–ç›®æ ‡åŸŸç‰¹å¾
                        with torch.no_grad():  # å‡å°‘å†…å­˜å ç”¨
                            _ = self.model(target_batch['img'])
                        target_features = self.feature_extractor.get_features()

                        if target_features is None:
                            LOGGER.warning("Failed to extract target domain features.")
                            continue

                        # åˆ¤åˆ«å™¨è®­ç»ƒ - æºåŸŸ (ç»™å®šæ ‡ç­¾0)
                        self.optimizer_D.zero_grad()
                        # åˆ†ç¦»ç‰¹å¾ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
                        source_features_detached = source_features.detach()
                        D_out_source = self.discriminator(source_features_detached)
                        D_source_label = torch.FloatTensor(D_out_source.data.size()).fill_(self.source_label).to(
                            self.device)
                        D_source_loss = F.mse_loss(D_out_source, D_source_label)

                        # åˆ¤åˆ«å™¨è®­ç»ƒ - ç›®æ ‡åŸŸ (ç»™å®šæ ‡ç­¾1)
                        target_features_detached = target_features.detach()
                        D_out_target = self.discriminator(target_features_detached)
                        D_target_label = torch.FloatTensor(D_out_target.data.size()).fill_(self.target_label).to(
                            self.device)
                        D_target_loss = F.mse_loss(D_out_target, D_target_label)

                        # æ€»åˆ¤åˆ«å™¨æŸå¤±å¹¶æ›´æ–°
                        D_loss = (D_source_loss + D_target_loss) / 2
                        D_loss.backward()
                        self.optimizer_D.step()

                        # æ˜ç¡®é‡Šæ”¾ä¸å†éœ€è¦çš„å¼ é‡
                        del source_features_detached, target_features_detached
                        del D_out_source, D_out_target

                        # æºåŸŸç‰¹å¾å¯¹æŠ—è®­ç»ƒ (æ··æ·†åˆ¤åˆ«å™¨)
                        self.optimizer.zero_grad()
                        source_D_out = self.discriminator(source_features)
                        # è¿™é‡Œæˆ‘ä»¬å¸Œæœ›æºåŸŸç‰¹å¾è¢«åˆ¤åˆ«ä¸ºç›®æ ‡åŸŸ
                        G_source_loss = F.mse_loss(source_D_out, D_target_label)
                        G_source_loss.backward()

                        # è®°å½•æŸå¤±
                        if self.args.amp:
                            self.scaler.step(self.optimizer)
                            self.scaler.update()
                        else:
                            self.optimizer.step()

                        # æ‰“å°åŸŸé€‚åº”æŸå¤±ä¿¡æ¯
                        if batch_idx % 10 == 0:
                            LOGGER.info(
                                f"{colorstr('green', 'bold', 'Domain Adapt')} Epoch: {epoch}, Batch: {batch_idx}, "
                                f"D_loss: {D_loss.item():.4f}, "
                                f"G_loss: {G_source_loss.item():.4f}")

                    except Exception as e:
                        LOGGER.error(f"Error in domain adaptation training: {e}")
                        import traceback
                        LOGGER.error(traceback.format_exc())

                    # æ˜ç¡®é‡Šæ”¾ä¸å†éœ€è¦çš„ç‰¹å¾
                    if 'source_features' in locals():
                        del source_features
                    if 'target_features' in locals():
                        del target_features

                # æ‰§è¡Œä½™ä¸‹çš„æ ‡å‡†è®­ç»ƒæ­¥éª¤
                if self.args.amp:
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    self.optimizer.step()

                self.optimizer.zero_grad()

                # è°ƒç”¨å›è°ƒå‡½æ•°
                self.run_callbacks('on_train_batch_end')

                # æ›´æ–°è¿›åº¦æ¡
                self.update_pbar(pbar, batch_idx, epoch)

                # ä¸»åŠ¨è§¦å‘åƒåœ¾å›æ”¶ï¼ˆåœ¨GPUä¸Šå¯ä»¥ä¸é‚£ä¹ˆé¢‘ç¹ï¼‰
                if batch_idx % 50 == 0:
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    else:
                        gc.collect()

            # å¤„ç†æ¯ä¸ªepochç»“æŸæ—¶çš„æ“ä½œ
            self.run_callbacks('on_train_epoch_end')

            # æ‰§è¡ŒéªŒè¯
            if (epoch + 1) % self.args.val_interval == 0:
                self.validate()

            # ä¿å­˜æ¨¡å‹
            self.save_model()

            # è°ƒç”¨å›è°ƒå‡½æ•°
            self.run_callbacks('on_fit_epoch_end')

            # æ£€æŸ¥æå‰ç»ˆæ­¢
            if self.stopper.possible_stop:
                LOGGER.info(
                    f'Stopping training early as no improvement observed in last {self.stopper.patience} epochs.')
                break

        # è®­ç»ƒå®Œæˆçš„æ“ä½œ
        self.run_callbacks('on_train_end')
        if world_size > 1 and RANK == 0:
            LOGGER.info(f"Training completed successfully after {epoch + 1} epochs.")

        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        self.run_callbacks('teardown')

    def update_pbar(self, pbar, batch_idx, epoch):
        """æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤º"""
        # è·å–å†…å­˜ä¿¡æ¯
        mem = f'{torch.cuda.memory_reserved() / 1E9:.3g}G' if torch.cuda.is_available() else 'CPU'

        # å¦‚æœæ˜¯tqdmè¿›åº¦æ¡å¯¹è±¡ï¼Œæ›´æ–°æè¿°
        if RANK in (-1, 0) and hasattr(pbar, 'set_description'):
            pbar.set_description(
                f"{epoch + 1}/{self.epochs} {mem} {self.loss_items[0]:.4f} {self.loss_items[1]:.4f} {self.loss_items[2]:.4f}"
            )

    def preprocess_batch(self, batch):
        """é¢„å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼Œç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šå’Œæ­£ç¡®çš„æ•°æ®ç±»å‹"""
        # å¦‚æœæ‰¹æ¬¡ä¸ºç©ºï¼ˆå¯èƒ½æ˜¯ç›®æ ‡åŸŸæ²¡æœ‰æ ‡ç­¾ï¼‰ï¼Œåˆ™åˆ›å»ºç©ºå­—å…¸
        if batch is None:
            return {'img': None}

        # å°†å›¾åƒç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼Œå¹¶ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        if 'img' in batch:
            # æ£€æŸ¥å›¾åƒæ•°æ®ç±»å‹å¹¶è¿›è¡Œå¿…è¦çš„è½¬æ¢
            img = batch['img']

            # å¦‚æœå›¾åƒæ˜¯æµ®ç‚¹å‹ï¼Œç¡®ä¿å·²ç»å½’ä¸€åŒ–
            if img.dtype == torch.float32:
                # ç¡®ä¿æ•°å€¼èŒƒå›´åœ¨[0,1]
                if img.max() > 1.0:
                    img = img / 255.0
            # å¦‚æœå›¾åƒæ˜¯æ•´å‹ï¼Œè½¬æ¢ä¸ºæµ®ç‚¹å‹å¹¶å½’ä¸€åŒ–
            elif img.dtype == torch.uint8:
                img = img.float() / 255.0

            # å°†å¤„ç†åçš„å›¾åƒç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            batch['img'] = img.to(self.device, non_blocking=True)

        # ç¡®ä¿æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å…ƒç´ éƒ½åœ¨ç›¸åŒè®¾å¤‡ä¸Š
        for k in batch:
            if k != 'img' and torch.is_tensor(batch[k]):
                batch[k] = batch[k].to(self.device, non_blocking=True)

        # ç‰¹åˆ«å¤„ç†batch_idxï¼Œç¡®ä¿å®ƒå­˜åœ¨ä¸”åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if 'batch_idx' not in batch and 'cls' in batch and 'bboxes' in batch:
            # è®¡ç®—æ¯ä¸ªæ ‡ç­¾å¯¹åº”çš„æ‰¹æ¬¡ç´¢å¼•
            cls_tensor = batch['cls']
            if len(cls_tensor.shape) == 1:
                num_labels = cls_tensor.shape[0]
            else:
                num_labels = cls_tensor.shape[0] * cls_tensor.shape[1]

            # åˆ›å»ºæ‰¹æ¬¡ç´¢å¼•å¼ é‡
            if num_labels > 0:
                # å¦‚æœæ ‡ç­¾ä¸ä¸ºç©ºï¼Œä¸ºæ¯ä¸ªæ ‡ç­¾åˆ†é…æ‰¹æ¬¡ç´¢å¼•
                # å‡è®¾æ¯ä¸ªå›¾åƒæœ‰ç›¸åŒæ•°é‡çš„æ ‡ç­¾
                batch_size = batch['img'].shape[0]
                labels_per_image = num_labels // batch_size
                batch['batch_idx'] = torch.arange(batch_size, device=self.device).repeat_interleave(labels_per_image)
            else:
                # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œåˆ›å»ºç©ºå¼ é‡
                batch['batch_idx'] = torch.tensor([], device=self.device)

        return batch

    def save_model(self):
        """ä¿å­˜åŒ…å«åŸŸé€‚åº”ç»„ä»¶çš„æ¨¡å‹"""
        # ä¿å­˜æ ‡å‡†æ£€æµ‹æ¨¡å‹
        super().save_model()

        # å¦‚æœå¯ç”¨äº†åŸŸé€‚åº”ï¼Œè¿˜ä¿å­˜åˆ¤åˆ«å™¨
        if self.domain_adapt_enabled and self.discriminator is not None:
            discriminator = de_parallel(self.discriminator)
            disc_path = str(self.save_dir / f'discriminator_{self.epoch}.pt')
            torch.save(discriminator.state_dict(), disc_path)
            LOGGER.info(f"Saved discriminator to {disc_path}")