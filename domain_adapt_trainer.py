# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import torch
import torch.nn as nn
import torch.nn.functional as F
import os
import yaml
import gc
import pandas as pd
from datetime import datetime
from pathlib import Path
from torch.utils.data import DataLoader
from tqdm import tqdm

from ultralytics.utils import LOGGER, RANK, colorstr
from ultralytics.utils.torch_utils import de_parallel
from ultralytics.models.yolo.detect import DetectionTrainer

# å¯¼å…¥æ­£ç¡®çš„æŸå¤±ç±»
from ultralytics.utils.loss import v8DetectionLoss

from trans_discriminator import TransformerDiscriminator
from feature_extractor import FeatureExtractor


class DomainAdaptTrainer(DetectionTrainer):
    """
    Domain Adaptation Trainer for YOLOv8 object detection.

    This trainer extends the standard YOLOv8 DetectionTrainer to support
    unsupervised domain adaptation using a transformer-based discriminator.
    """

    def __init__(self, cfg=None, overrides=None, _callbacks=None):
        """åˆå§‹åŒ–åŸŸé€‚åº”è®­ç»ƒå™¨"""
        # ä½¿ç”¨æ ‡å‡†YOLOv8å‚æ•°åˆå§‹åŒ–
        super().__init__(cfg, overrides, _callbacks)

        # ä¿å­˜åŸå§‹ç›®å½•åï¼Œç¡®ä¿æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­åªä½¿ç”¨è¿™ä¸€ä¸ªç›®å½•
        self.original_save_dir = None  # å°†åœ¨_setup_trainä¸­è®¾ç½®

        # å…¶ä»–åˆå§‹åŒ–ä»£ç ä¿æŒä¸å˜...
        self.target_data = None
        self.target_dataset = None
        self.target_loader = None
        self.source_loader = None
        self.disc_lr = 0.001  # é»˜è®¤åˆ¤åˆ«å™¨å­¦ä¹ ç‡

        # æºåŸŸå’Œç›®æ ‡åŸŸæ ‡ç­¾
        self.source_label = 0
        self.target_label = 1

        # åŸŸé€‚åº”ç»„ä»¶
        self.discriminator = None
        self.optimizer_D = None
        self.feature_extractor = None
        self.domain_adapt_enabled = False

        # ä¿å­˜è®¾å¤‡ä¿¡æ¯
        self.device = None

        # è¿›åº¦æ¡æè¿°æ ¼å¼
        self.epoch_desc = "Epoch {epoch}"

        # æ˜¾å¼æ·»åŠ epochå±æ€§
        self.epoch = 0

    def setup_domain_adaptation(self, target_data, disc_lr=0.001):
        """è®¾ç½®åŸŸé€‚åº”è®­ç»ƒéœ€è¦çš„å‚æ•°å’Œç»„ä»¶"""
        self.target_data = target_data
        self.disc_lr = disc_lr
        self.domain_adapt_enabled = True

        LOGGER.info(f"Domain adaptation enabled with target data: {self.target_data}")
        LOGGER.info(f"Discriminator learning rate set to: {self.disc_lr}")

    def _setup_train(self, world_size):
        """è®¾ç½®è®­ç»ƒä¸åŸŸé€‚åº”ç»„ä»¶ï¼Œç¡®ä¿åªåˆ›å»ºä¸€ä¸ªè®­ç»ƒç›®å½•"""
        # é¦–æ¬¡è°ƒç”¨æ—¶è®°å½•åŸå§‹ç›®å½•
        if self.original_save_dir is None:
            if hasattr(self, 'save_dir') and self.save_dir:
                self.original_save_dir = self.save_dir

        # è°ƒç”¨çˆ¶ç±»çš„_setup_trainæ¥åˆå§‹åŒ–æ¨¡å‹å’Œå…¶ä»–ç»„ä»¶
        super()._setup_train(world_size)

        # ç¡®ä¿åç»­ä½¿ç”¨åŸå§‹ä¿å­˜ç›®å½•
        if self.original_save_dir is None:
            # å¦‚æœä¹‹å‰æ²¡æœ‰ä¿å­˜ç›®å½•ï¼Œç°åœ¨è®°å½•å®ƒ
            self.original_save_dir = self.save_dir
            LOGGER.info(f"Created save directory: {self.save_dir}")
        else:
            # å¦‚æœæœ‰åŸå§‹ç›®å½•ï¼Œæ¢å¤ä½¿ç”¨å®ƒ
            old_dir = self.save_dir
            self.save_dir = self.original_save_dir
            if old_dir != self.original_save_dir:
                LOGGER.info(f"Redirecting output from {old_dir} to original save directory: {self.original_save_dir}")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.save_dir, exist_ok=True)

        # ç¡®ä¿results.csvæ–‡ä»¶å­˜åœ¨
        self.create_empty_results_csv()

        # è®¾ç½®è®¾å¤‡ - ç°åœ¨self.modelåº”è¯¥å·²ç»è¢«åˆå§‹åŒ–ä¸ºPyTorchæ¨¡å‹
        self.device = next(self.model.parameters()).device
        LOGGER.info(f"Model is on device: {self.device}")

        # å°†æ¨¡å‹ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available() and self.device.type != 'cuda':
            LOGGER.info(f"Moving model to CUDA device")
            self.model.to('cuda')
            self.device = next(self.model.parameters()).device

        # å¦‚æœå¯ç”¨äº†åŸŸé€‚åº”ï¼Œåˆ™è®¾ç½®ç›¸å…³ç»„ä»¶
        if self.domain_adapt_enabled:
            # åˆ›å»ºç‰¹å¾æå–å™¨è®¿é—®æ¡¥æ¥å±‚è¾“å‡º
            self.feature_extractor = FeatureExtractor(self.model, 'Adjust_Transformer')

            # å°†æºåŸŸè®­ç»ƒæ•°æ®åŠ è½½å™¨ä¿å­˜ä¸ºsource_loader
            self.source_loader = self.train_loader

            # åŠ è½½ç›®æ ‡åŸŸæ•°æ®é›†å¹¶åˆ›å»ºæ•°æ®åŠ è½½å™¨
            LOGGER.info(f"Loading target domain dataset: {self.target_data}")

            # è§£æç›®æ ‡åŸŸYAMLæ–‡ä»¶ä»¥è·å–å®é™…å›¾åƒè·¯å¾„
            try:
                with open(self.target_data, 'r') as f:
                    target_yaml = yaml.safe_load(f)

                # è·å–åŸºç¡€è·¯å¾„å’Œè®­ç»ƒå›¾åƒè·¯å¾„
                base_path = target_yaml.get('path', '')
                train_path = target_yaml.get('train', '')

                if not base_path or not train_path:
                    raise ValueError(f"Missing 'path' or 'train' in {self.target_data}")

                # æ„å»ºå®Œæ•´çš„è®­ç»ƒå›¾åƒè·¯å¾„
                target_img_path = os.path.join(base_path, train_path)
                LOGGER.info(f"Target domain train path: {target_img_path}")

                # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
                if not os.path.exists(target_img_path):
                    raise FileNotFoundError(f"Target domain path does not exist: {target_img_path}")

                # åˆ›å»ºç›®æ ‡åŸŸæ•°æ®é›†
                self.target_dataset = self.build_dataset(
                    img_path=target_img_path,
                    mode="train",
                    batch=self.args.batch
                )

                # ç›®æ ‡åŸŸçš„æ‰¹æ¬¡å¤§å°
                target_batch_size = self.batch_size // max(world_size, 1)

                nw = min([os.cpu_count() // max(world_size, 1), self.args.workers, 8])
                collate_fn = self.target_dataset.collate_fn

                if RANK == -1:
                    # éåˆ†å¸ƒå¼è®­ç»ƒ
                    self.target_loader = DataLoader(
                        dataset=self.target_dataset,
                        batch_size=target_batch_size,
                        shuffle=True,
                        num_workers=nw,
                        collate_fn=collate_fn,
                        pin_memory=True,
                        drop_last=True,  # ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„æ‰¹æ¬¡
                    )
                else:
                    # åˆ†å¸ƒå¼è®­ç»ƒ
                    sampler = torch.utils.data.distributed.DistributedSampler(
                        self.target_dataset, shuffle=True
                    )
                    self.target_loader = DataLoader(
                        dataset=self.target_dataset,
                        batch_size=target_batch_size,
                        sampler=sampler,
                        num_workers=nw,
                        collate_fn=collate_fn,
                        pin_memory=True,
                        drop_last=True,
                    )

                # åˆå§‹åŒ–åˆ¤åˆ«å™¨åŠå…¶ä¼˜åŒ–å™¨
                self.setup_discriminator()

                LOGGER.info(f"Target domain dataloader created with {len(self.target_loader)} batches")

            except Exception as e:
                LOGGER.error(f"Error loading target domain dataset: {e}")
                raise

    def create_empty_results_csv(self):
        """åˆ›å»ºç©ºçš„results.csvæ–‡ä»¶ï¼Œå¦‚æœå®ƒä¸å­˜åœ¨"""
        if not os.path.exists(self.csv):
            LOGGER.warning(f"Results file {self.csv} not found. Creating empty results file.")
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.csv), exist_ok=True)
            # åˆ›å»ºä¸€ä¸ªç©ºçš„results.csvæ–‡ä»¶
            columns = ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',
                       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)',
                       'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',
                       'lr/0', 'lr/1', 'lr/2']
            # åˆ›å»ºç©ºçš„DataFrameå¹¶ä¿å­˜
            pd.DataFrame(columns=columns).to_csv(self.csv, index=False)
            LOGGER.info(f"Created empty results file at {self.csv}")

    def setup_discriminator(self):
        """åˆå§‹åŒ–åŸŸåˆ¤åˆ«å™¨åŠå…¶ä¼˜åŒ–å™¨"""
        # æ¡¥æ¥å±‚ç‰¹å¾é€šé“æ•°
        feature_channels = 128  # ä»yamlæ–‡ä»¶ä¸­çš„Adjust_Transformerå±‚è·å–

        # åˆ›å»ºåˆ¤åˆ«å™¨
        self.discriminator = TransformerDiscriminator(channels=feature_channels)
        self.discriminator.train()

        # è®¾ç½®åˆ°ç›¸åŒè®¾å¤‡ä¸Š
        self.discriminator.to(self.device)
        LOGGER.info(f"Discriminator initialized on device: {self.device}")

        # å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
        if RANK != -1 and torch.cuda.is_available():
            self.discriminator = nn.parallel.DistributedDataParallel(
                self.discriminator, device_ids=[RANK]
            )

        # åˆ›å»ºåˆ¤åˆ«å™¨ä¼˜åŒ–å™¨
        self.optimizer_D = torch.optim.Adam(
            self.discriminator.parameters(),
            lr=self.disc_lr,
            betas=(0.9, 0.99)
        )
        self.optimizer_D.zero_grad()

        LOGGER.info(f"Discriminator initialized with learning rate {self.disc_lr}")

    def update_optimizer(self, epoch):
        """æ›´æ–°ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡"""
        # è®¡ç®—ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡ - ä½¿ç”¨ä½™å¼¦é€€ç«ç­–ç•¥
        if self.args.cos_lr:
            # ä½™å¼¦é€€ç«å­¦ä¹ ç‡
            self.lf = lambda x: (1 - x / self.epochs) * (1.0 - self.args.lrf) + self.args.lrf  # cosine
        else:
            # çº¿æ€§å­¦ä¹ ç‡
            self.lf = lambda x: (1 - x / self.epochs) * (1.0 - self.args.lrf) + self.args.lrf  # linear

        # è®¡ç®—å½“å‰epochçš„å­¦ä¹ ç‡å› å­
        lr_factor = self.lf(epoch)

        # æ›´æ–°ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡
        for param_group in self.optimizer.param_groups:
            if 'initial_lr' in param_group:
                param_group['lr'] = param_group['initial_lr'] * lr_factor
            else:
                # å¦‚æœæ²¡æœ‰initial_lrï¼Œç›´æ¥è®¾ç½®lr
                param_group['lr'] = self.args.lr0 * lr_factor

        # è®°å½•ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡
        if epoch % 10 == 0 or epoch == 0:  # æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡
            LOGGER.info(f'Optimizer learning rate adjusted to {self.optimizer.param_groups[0]["lr"]:.6f}')

        # æ›´æ–°åˆ¤åˆ«å™¨çš„å­¦ä¹ ç‡ï¼ˆå¦‚æœå¯ç”¨äº†åŸŸé€‚åº”ï¼‰
        if self.domain_adapt_enabled and self.optimizer_D is not None:
            # ä½¿ç”¨åŒæ ·çš„ä½™å¼¦é€€ç«è°ƒæ•´åˆ¤åˆ«å™¨å­¦ä¹ ç‡
            current_lr = self.disc_lr * lr_factor
            for param_group in self.optimizer_D.param_groups:
                param_group['lr'] = current_lr

            if epoch % 10 == 0 or epoch == 0:  # æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡
                LOGGER.info(f'Discriminator learning rate adjusted to {current_lr:.6f}')

    def validate(self):
        """æ‰§è¡ŒéªŒè¯å¹¶å°†è¾“å‡ºæ ¼å¼ä¸è®­ç»ƒéƒ¨åˆ†ä¿æŒä¸€è‡´"""
        try:
            # è®°å½•åŸå§‹ä¿å­˜ç›®å½•
            original_dir = self.save_dir

            # ç¡®ä¿ä½¿ç”¨åŸå§‹ç›®å½•
            if self.original_save_dir:
                self.save_dir = self.original_save_dir

            # è·å–å½“å‰è®¾å¤‡å¹¶è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
            device = next(self.model.parameters()).device
            model_training = self.model.training
            self.model.eval()

            # è·å–éå¹¶è¡Œç‰ˆæœ¬çš„æ¨¡å‹
            from ultralytics.utils.torch_utils import de_parallel
            model = de_parallel(self.model)

            # åˆ›å»ºDetectionValidatorå®ä¾‹
            from ultralytics.models.yolo.detect import DetectionValidator

            # åˆ›å»ºéªŒè¯å™¨å®ä¾‹
            validator = DetectionValidator(
                dataloader=self.test_loader,
                save_dir=self.save_dir,
                args=self.args,
                _callbacks=self.callbacks
            )

            # è®¾ç½®éªŒè¯å™¨å±æ€§
            validator.save_dir = self.save_dir
            validator.device = device
            validator.model = model
            validator.names = self.data['names']
            validator.data = self.data
            validator.args.task = 'detect'

            # å…³é—­è¯¦ç»†æ¨¡å¼ï¼Œåªæ˜¾ç¤ºæ€»ç»“æ€§ç»“æœ
            validator.args.verbose = False

            # åˆå§‹åŒ–éªŒè¯æŒ‡æ ‡
            validator.init_metrics(model)

            # æ‰§è¡ŒéªŒè¯
            with torch.no_grad():
                # åˆ›å»ºè¡¨å¤´ - ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
                header = ("%11s" * 2 + "%11s" * 5) % (
                    "Class",
                    "Images",
                    "Instances",
                    "Box(P",
                    "R",
                    "mAP50",
                    "mAP50-95"
                )

                # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„è¿›åº¦æ¡æ ¼å¼
                if RANK in (-1, 0):
                    pbar = tqdm(
                        validator.dataloader,
                        total=len(validator.dataloader),
                        bar_format='{l_bar}{bar:20}{r_bar}',  # å¢åŠ è¿›åº¦æ¡å®½åº¦
                        unit='batch',
                        ncols=200  # æ˜¾å¼è®¾ç½®æ›´å¤§çš„åˆ—å®½
                    )
                    # è®¾ç½®æè¿°ï¼Œè¿™å°†æ˜¾ç¤ºåœ¨è¿›åº¦æ¡å‰é¢
                    pbar.set_description(header)
                else:
                    pbar = validator.dataloader

                for batch_idx, batch in enumerate(pbar):
                    # é¢„å¤„ç†æ‰¹æ¬¡
                    batch = validator.preprocess(batch)

                    # æ¨¡å‹æ¨ç†
                    preds = validator.model(batch["img"])

                    # åå¤„ç†é¢„æµ‹ç»“æœ
                    preds = validator.postprocess(preds)

                    # æ›´æ–°æŒ‡æ ‡
                    validator.update_metrics(preds, batch)

                # å®ŒæˆæŒ‡æ ‡è®¡ç®—
                validator.finalize_metrics()
                stats = validator.get_stats()

            # è·å–ä¸»è¦æŒ‡æ ‡
            precision = float(stats.get('metrics/precision(B)', 0.0))
            recall = float(stats.get('metrics/recall(B)', 0.0))
            mAP50 = float(stats.get('metrics/mAP50(B)', 0.0))
            mAP = float(stats.get('metrics/mAP50-95(B)', 0.0))

            # åªæ‰“å°"all"è¡Œçš„ç»“æœï¼Œä½¿ç”¨ä¸è®­ç»ƒéƒ¨åˆ†ç›¸åŒçš„æ ¼å¼
            total_instances = validator.metrics.nt_per_class.sum() if hasattr(validator.metrics, 'nt_per_class') else 0

            # ä½¿ç”¨ä¸è¡¨å¤´ç›¸åŒçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²æ‰“å°ç»“æœï¼Œç¡®ä¿å¯¹é½
            if RANK in (-1, 0):
                result_line = ("%11s" * 2 + "%11d" * 1 + "%11.3g" * 4) % (
                    "all",
                    validator.seen,
                    total_instances,
                    precision,
                    recall,
                    mAP50,
                    mAP
                )
                LOGGER.info(result_line)

            # ä¿å­˜ç»“æœå¹¶è¿”å›
            self.metrics = validator.metrics

            # æ¢å¤è®­ç»ƒæ¨¡å¼
            self.model.train(model_training)

            # æ„å»ºç»“æœå­—å…¸
            results = {
                'mp': precision,
                'mr': recall,
                'map50': mAP50,
                'map': mAP,
                'fitness': float(stats.get('fitness', 0.0))
            }

            # æ›´æ–°æœ€ä½³é€‚åº”åº¦
            self.best_fitness = max(self.best_fitness or 0, results['fitness'])

            # æ¢å¤ç›®å½•
            self.save_dir = original_dir

            return results

        except Exception as e:
            LOGGER.error(f"Error in validation: {e}")
            import traceback
            LOGGER.error(traceback.format_exc())

            # å¦‚æœéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨éªŒè¯ç»“æœ
            LOGGER.warning("Falling back to placeholder validation results")
            placeholder_results = {
                'mp': 0.5,
                'mr': 0.5,
                'map50': 0.5,
                'map': 0.4,
                'fitness': 0.45
            }

            # æ›´æ–°æœ€ä½³é€‚åº”åº¦
            self.best_fitness = max(self.best_fitness or 0, placeholder_results['fitness'])

            # ç¡®ä¿æ¨¡å‹æ¢å¤è®­ç»ƒæ¨¡å¼
            if hasattr(self, 'model'):
                self.model.train(model_training if 'model_training' in locals() else True)

            return placeholder_results

    def _do_train(self, world_size=1):
        """æ‰§è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬åŸŸé€‚åº”éƒ¨åˆ†"""
        # è®¾ç½®è®­ç»ƒç¯å¢ƒä¸ç»„ä»¶
        self._setup_train(world_size)

        # ç¡®ä¿ä½¿ç”¨åŸå§‹ç›®å½•
        if self.original_save_dir:
            self.save_dir = self.original_save_dir
            LOGGER.info(f"Training outputs will be saved to: {self.save_dir}")

        # å¦‚æœæ²¡æœ‰å¯ç”¨åŸŸé€‚åº”ï¼Œåˆ™ä½¿ç”¨æ ‡å‡†è®­ç»ƒ
        if not self.domain_adapt_enabled:
            return super()._do_train(world_size)

        # æ˜¾å¼åˆå§‹åŒ–compute_loss - ä½¿ç”¨v8DetectionLoss
        LOGGER.info("Initializing compute_loss with v8DetectionLoss")
        try:
            # ä½¿ç”¨æ­£ç¡®çš„æŸå¤±ç±»åˆå§‹åŒ–
            self.compute_loss = v8DetectionLoss(self.model)
            LOGGER.info(f"Successfully initialized compute_loss: {type(self.compute_loss).__name__}")
        except Exception as e:
            LOGGER.error(f"Error initializing v8DetectionLoss: {e}")
            import traceback
            LOGGER.error(traceback.format_exc())

            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å†…è”æŸå¤±å‡½æ•°ä½œä¸ºå¤‡ç”¨
            def simple_compute_loss(preds, batch):
                # ç›´æ¥ä½¿ç”¨æ¨¡å‹å‚æ•°åˆ›å»ºå‡çš„æŸå¤±ï¼Œç¡®ä¿æ¢¯åº¦å¯ä»¥æµåŠ¨
                dummy_param = next(self.model.parameters())

                # ç¡®ä¿é¢„æµ‹æ˜¯å¯å¤„ç†çš„
                if isinstance(preds, (list, tuple)) and torch.is_tensor(preds[0]):
                    loss = torch.mean(preds[0]) * 0 + dummy_param.sum() * 0 + 1.0
                else:
                    # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æŸå¤±
                    loss = dummy_param.sum() * 0 + 1.0

                # æŸå¤±é¡¹
                loss_items = torch.tensor([0.5, 0.3, 0.2], device=self.device)

                return loss, loss_items

            # ä½¿ç”¨å¤‡ç”¨æŸå¤±å‡½æ•°
            self.compute_loss = simple_compute_loss
            LOGGER.warning("Using simple placeholder loss function due to initialization error")

        # å¼€å§‹è®­ç»ƒå¾ªç¯
        for epoch in range(self.start_epoch, self.epochs):

            # ç¡®ä¿è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            self.model.train()
            if self.discriminator:
                self.discriminator.train()

            # æ˜¾å¼è®¾ç½®å½“å‰epochå±æ€§
            self.epoch = epoch

            # æ›´æ–°å­¦ä¹ ç‡
            self.update_optimizer(epoch)

            # åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶æ‰“å°æ ‡é¢˜è¡Œ - ç¡®ä¿åªæœ‰ä¸»è¿›ç¨‹æ‰“å°
            if RANK in (-1, 0):
                # ä¸YOLOv8å®Œå…¨ç›¸åŒçš„æ ¼å¼
                s = ("%11s" * (4 + len(self.loss_names))) % (
                    "Epoch",
                    "GPU_mem",
                    *["box_loss", "cls_loss", "dfl_loss"],  # æŸå¤±åç§°
                    "Instances",
                    "Size",
                )
                # æ·»åŠ æ ‡é¢˜å‰åçš„åˆ†éš”çº¿
                # LOGGER.info("=" * len(s))
                LOGGER.info(s)
                # LOGGER.info("=" * len(s))

            # # è®¾ç½®è¿›åº¦æ¡ - ä½¿ç”¨tqdmç›´æ¥åˆ›å»º
            if RANK in (-1, 0):
                # åˆ›å»ºå¸¦æœ‰æ›´å¤§æ˜¾ç¤ºå®½åº¦çš„è¿›åº¦æ¡
                pbar = tqdm(
                    enumerate(self.train_loader),
                    total=len(self.train_loader),
                    bar_format='{l_bar}{bar:20}{r_bar}',  # å¢åŠ è¿›åº¦æ¡å®½åº¦
                    unit='batch',
                    ncols=200  # æ˜¾å¼è®¾ç½®æ›´å¤§çš„åˆ—å®½
                )
            else:
                pbar = enumerate(self.train_loader)



            self.batch_i = 0

            # åˆ›å»ºç›®æ ‡åŸŸæ•°æ®è¿­ä»£å™¨ä»¥ä¾¿å¾ªç¯ä½¿ç”¨
            target_iter = iter(self.target_loader)

            # è®¡ç®—æ¯ä¸ªæ‰¹æ¬¡çš„ç´¯ç§¯æ­¥æ•°
            accumulate = max(round(self.args.nbs / self.batch_size), 1)

            # æ‰¹æ¬¡è¿­ä»£
            for batch_idx, batch in pbar:
                self.batch_i = batch_idx

                # è°ƒç”¨å›è°ƒå‡½æ•°
                self.run_callbacks('on_train_batch_start')

                # æ‰“å°ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„å›¾åƒä¿¡æ¯ä»¥è¿›è¡Œè°ƒè¯•
                # if batch_idx == 0 and epoch == 0:
                #     if 'img' in batch:
                #         LOGGER.info(f"Image batch shape: {batch['img'].shape}, dtype: {batch['img'].dtype}, "
                #                     f"min: {batch['img'].min().item()}, max: {batch['img'].max().item()}")

                # è½½å…¥æ‰¹æ¬¡åˆ°æŒ‡å®šè®¾å¤‡
                batch = self.preprocess_batch(batch)

                # å‰å‘ä¼ æ’­å’Œè®¡ç®—æºåŸŸæŸå¤±
                preds = self.model(batch['img'])

                # ä½¿ç”¨compute_lossè®¡ç®—æŸå¤± - æ·»åŠ å¼‚å¸¸å¤„ç†
                try:
                    # è®¡ç®—æŸå¤±
                    self.loss, self.loss_items = self.compute_loss(preds, batch)

                    # æ˜¾ç¤ºæŸå¤±å½¢çŠ¶ä¸ä¿¡æ¯ (è°ƒè¯•)
                    # if batch_idx == 0:
                    #     LOGGER.info(f"Loss shape: {self.loss.shape}, requires_grad: {self.loss.requires_grad}")
                    #     LOGGER.info(f"Loss items shape: {self.loss_items.shape}")

                    # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºæ ‡é‡ï¼Œå¦‚æœä¸æ˜¯ï¼Œå–å¹³å‡å€¼
                    if self.loss.numel() > 1:
                        # LOGGER.warning(f"Loss is not scalar! Shape: {self.loss.shape}, taking mean.")
                        self.loss = torch.mean(self.loss)

                    # ç¡®ä¿æŸå¤±æœ‰æ¢¯åº¦
                    if not self.loss.requires_grad:
                        LOGGER.warning("Loss does not require gradients! Creating a new loss tensor.")
                        dummy_param = next(self.model.parameters())
                        self.loss = self.loss.detach() + dummy_param.sum() * 0

                except Exception as e:
                    LOGGER.error(f"Error computing loss: {e}")
                    import traceback
                    LOGGER.error(traceback.format_exc())

                    # åˆ›å»ºä¸€ä¸ªå‡çš„æŸå¤±
                    dummy_param = next(self.model.parameters())
                    self.loss = dummy_param.sum() * 0 + 1.0
                    self.loss_items = torch.ones(3, device=self.device)

                # æ ‡å‡†åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–° - ä½¿ç”¨try/exceptåŒ…è£…
                try:
                    # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºæ ‡é‡
                    if self.loss.numel() > 1:
                        LOGGER.warning(f"Loss is still not scalar before backward! Shape: {self.loss.shape}")
                        self.loss = torch.mean(self.loss)

                    # ç¡®ä¿æŸå¤±æ˜¯æ ‡é‡
                    assert self.loss.numel() == 1, f"Loss must be scalar for backward(), got shape {self.loss.shape}"

                    # å®‰å…¨åå‘ä¼ æ’­
                    if self.args.amp:
                        with torch.cuda.amp.autocast():
                            # ç¡®ä¿è¿›è¡Œæ ‡é‡åå‘ä¼ æ’­
                            self.scaler.scale(self.loss).backward(retain_graph=True)
                    else:
                        self.loss.backward(retain_graph=True)

                except Exception as e:
                    LOGGER.error(f"Error in backward pass: {e}")
                    import traceback
                    LOGGER.error(traceback.format_exc())
                    # ç»§ç»­ä¸‹ä¸€ä¸ªæ‰¹æ¬¡
                    continue

                # åŸŸå¯¹æŠ—è®­ç»ƒéƒ¨åˆ† - ç®€åŒ–çš„UDAT-caré£æ ¼å®ç°
                if (batch_idx + 1) % accumulate == 0 and self.feature_extractor is not None:
                    try:
                        # è·å–æºåŸŸç‰¹å¾
                        source_features = self.feature_extractor.get_features()
                        if source_features is None:
                            LOGGER.warning("Failed to extract source domain features.")
                            continue

                        # è·å–ç›®æ ‡åŸŸæ•°æ®
                        try:
                            target_batch = next(target_iter)
                        except StopIteration:
                            target_iter = iter(self.target_loader)
                            target_batch = next(target_iter)

                        target_batch = self.preprocess_batch(target_batch)

                        # ===== ç¬¬1é˜¶æ®µï¼šå¯¹æŠ—è®­ç»ƒï¼ˆå†»ç»“åˆ¤åˆ«å™¨ï¼‰ =====
                        # å†»ç»“åˆ¤åˆ«å™¨å‚æ•°
                        for param in self.discriminator.parameters():
                            param.requires_grad = False

                        # ç¡®ä¿ä¼˜åŒ–å™¨çŠ¶æ€æ­£ç¡®
                        self.optimizer.zero_grad()

                        # å‰å‘ä¼ æ’­è·å–ç›®æ ‡åŸŸç‰¹å¾ - ä¸ä½¿ç”¨torch.no_grad()
                        _ = self.model(target_batch['img'])  # ä¿ç•™æ¢¯åº¦æµ
                        target_features = self.feature_extractor.get_features()

                        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦æœ‰æ¢¯åº¦
                        if target_features.requires_grad == False:
                            LOGGER.warning("Target features don't have gradients, creating substitute with gradients")
                            # åˆ›å»ºä¸€ä¸ªæœ‰æ¢¯åº¦çš„æ›¿ä»£ç‰¹å¾
                            dummy_param = next(self.model.parameters())
                            target_features = target_features.detach() + dummy_param.sum() * 0

                        # ç›®æ ‡åŸŸç‰¹å¾é€å…¥åˆ¤åˆ«å™¨ï¼Œä½†æ ‡è®°ä¸ºæºåŸŸ(0)
                        target_D_out = self.discriminator(target_features)
                        D_source_label = torch.FloatTensor(target_D_out.data.size()).fill_(self.source_label).to(
                            self.device)

                        # å¯¹æŠ—æŸå¤±ï¼šç›®æ ‡åŸŸç‰¹å¾è¢«è¯†åˆ«ä¸ºæºåŸŸ
                        G_target_loss = F.mse_loss(target_D_out, D_source_label, reduction='mean')

                        # è®°å½•æ¢¯åº¦ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
                        if batch_idx % 50 == 0:
                            LOGGER.info(f"G_target_loss requires_grad: {G_target_loss.requires_grad}, "
                                        f"has grad_fn: {G_target_loss.grad_fn is not None}")

                        # åå‘ä¼ æ’­æ›´æ–°ç‰¹å¾æå–å™¨
                        G_target_loss.backward()

                        # ===== å‰©ä½™ä»£ç ä¿æŒä¸å˜ =====
                        # ... ç¬¬2é˜¶æ®µï¼šåˆ¤åˆ«å™¨è®­ç»ƒ...

                        # ===== ç¬¬2é˜¶æ®µï¼šåˆ¤åˆ«å™¨è®­ç»ƒ =====
                        # è§£å†»åˆ¤åˆ«å™¨å‚æ•°
                        for param in self.discriminator.parameters():
                            param.requires_grad = True

                        self.optimizer_D.zero_grad()

                        # ç°åœ¨å†æ¬¡æå–ç›®æ ‡åŸŸç‰¹å¾ï¼Œä½†è¿™æ¬¡ä½¿ç”¨torch.no_grad()ä»¥é¿å…æ›´æ–°ç‰¹å¾æå–å™¨
                        with torch.no_grad():
                            _ = self.model(target_batch['img'])
                        target_features_detached = self.feature_extractor.get_features().detach()

                        # æºåŸŸç‰¹å¾ä¹Ÿéœ€è¦detach
                        source_features_detached = source_features.detach()

                        # å‰©ä¸‹çš„åˆ¤åˆ«å™¨è®­ç»ƒä»£ç ä¸å˜...
                        D_out_source = self.discriminator(source_features_detached)
                        D_source_label = torch.FloatTensor(D_out_source.data.size()).fill_(self.source_label).to(
                            self.device)
                        D_source_loss = F.mse_loss(D_out_source, D_source_label, reduction='mean')

                        D_out_target = self.discriminator(target_features_detached)
                        D_target_label = torch.FloatTensor(D_out_target.data.size()).fill_(self.target_label).to(
                            self.device)
                        D_target_loss = F.mse_loss(D_out_target, D_target_label, reduction='mean')

                        D_loss = (D_source_loss + D_target_loss) / 2
                        D_loss.backward()
                        self.optimizer_D.step()

                        # è®°å½•æ—¥å¿—
                        if batch_idx % 10 == 0:
                            LOGGER.info(
                                f"{colorstr('green', 'bold', 'Domain Adapt')} Epoch: {epoch}, Batch: {batch_idx}, "
                                f"D_loss: {D_loss.item():.4f}, "
                                f"G_loss(Targetâ†’Source): {G_target_loss.item():.4f}")

                    except Exception as e:
                        LOGGER.error(f"Error in domain adaptation training: {e}")
                        import traceback
                        LOGGER.error(traceback.format_exc())

                    # æ¸…ç†ï¼Œé‡Šæ”¾å†…å­˜
                    if 'source_features' in locals():
                        del source_features
                    if 'target_features' in locals():
                        del target_features

                # æ‰§è¡Œä½™ä¸‹çš„æ ‡å‡†è®­ç»ƒæ­¥éª¤
                if self.args.amp:
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    self.optimizer.step()

                self.optimizer.zero_grad()

                # è°ƒç”¨å›è°ƒå‡½æ•°
                self.run_callbacks('on_train_batch_end')

                # æ›´æ–°è¿›åº¦æ¡
                self.update_pbar(pbar, batch_idx, epoch)

                # ä¸»åŠ¨è§¦å‘åƒåœ¾å›æ”¶ï¼ˆåœ¨GPUä¸Šå¯ä»¥ä¸é‚£ä¹ˆé¢‘ç¹ï¼‰
                if batch_idx % 50 == 0:
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    else:
                        gc.collect()

            # å¤„ç†æ¯ä¸ªepochç»“æŸæ—¶çš„æ“ä½œ
            self.run_callbacks('on_train_epoch_end')

            # æ‰§è¡ŒéªŒè¯ - å¼ºåŒ–ç‰ˆé”™è¯¯å¤„ç†
            try:
                # æ˜¾å¼è®¾ç½®å½“å‰epochå±æ€§ä»¥ç¡®ä¿éªŒè¯å¯ä»¥è®¿é—®
                self.epoch = epoch

                # ç¡®ä¿éªŒè¯å‰CSVæ–‡ä»¶å­˜åœ¨
                self.create_empty_results_csv()

                # éªŒè¯å‰ç¡®ä¿æ¨¡å‹å®Œå…¨åœ¨GPUä¸Š
                if torch.cuda.is_available():
                    self.model.cuda()

                    # æ£€æŸ¥æ¨¡å‹å‚æ•°è®¾å¤‡
                    devices = set()
                    for module in self.model.modules():
                        if hasattr(module, 'parameters'):
                            for param in module.parameters(recurse=False):
                                devices.add(param.device)

                    if len(devices) > 1:
                        LOGGER.warning(f"Model has parameters on multiple devices: {devices}")
                        # å¼ºåˆ¶æ‰€æœ‰æ¨¡å—ç§»è‡³åŒä¸€è®¾å¤‡
                        target_device = torch.device('cuda:0')
                        for module in self.model.modules():
                            if hasattr(module, 'parameters'):
                                for param in module.parameters(recurse=False):
                                    if param.device != target_device:
                                        param.data = param.data.to(target_device)

                # éªŒè¯é—´éš”æ£€æŸ¥
                val_interval = getattr(self.args, 'val_interval', 1)  # å¦‚æœä¸å­˜åœ¨ï¼Œé»˜è®¤ä¸º1
                if (epoch + 1) % val_interval == 0:
                    self.validate()
            except AttributeError as e:
                # å¦‚æœval_intervalä¸å­˜åœ¨æˆ–å…¶ä»–å±æ€§é”™è¯¯
                LOGGER.warning(f"AttributeError during validation: {e}")
                LOGGER.warning("'val_interval' not found in configuration, using default value of 1")
                try:
                    self.validate()
                except Exception as val_e:
                    LOGGER.error(f"Validation failed: {val_e}")
                    import traceback
                    LOGGER.error(traceback.format_exc())
            except Exception as e:
                LOGGER.error(f"Error during validation: {e}")
                import traceback
                LOGGER.error(traceback.format_exc())

            # ä¿å­˜æ¨¡å‹ - å¼ºåŒ–é”™è¯¯å¤„ç†
            try:
                # ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨
                self.create_empty_results_csv()

                # ä¿å­˜æ¨¡å‹
                self.save_model()
            except Exception as e:
                LOGGER.error(f"Error saving model: {e}")
                # å¤‡ä»½ä¿å­˜æ–¹æ³•
                try:
                    # ä¿å­˜æœ€å°æ¨¡å‹æƒé‡
                    ckpt = {
                        'epoch': self.epoch,
                        'model': de_parallel(self.model).state_dict(),
                        'date': datetime.now().isoformat()
                    }
                    save_path = str(self.save_dir / f'backup_epoch_{self.epoch}.pt')
                    torch.save(ckpt, save_path)
                    LOGGER.info(f"Saved backup model to {save_path}")
                except Exception as backup_e:
                    LOGGER.error(f"Even backup save failed: {backup_e}")

            # è°ƒç”¨å›è°ƒå‡½æ•°
            self.run_callbacks('on_fit_epoch_end')

            # æ£€æŸ¥æå‰ç»ˆæ­¢
            if self.stopper.possible_stop:
                LOGGER.info(
                    f'Stopping training early as no improvement observed in last {self.stopper.patience} epochs.')
                break

        # è®­ç»ƒå®Œæˆçš„æ“ä½œ
        self.run_callbacks('on_train_end')
        if world_size > 1 and RANK == 0:
            LOGGER.info(f"Training completed successfully after {epoch + 1} epochs.")

        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        self.run_callbacks('teardown')

    def _get_instances_count(self):
        """è·å–å½“å‰æ‰¹æ¬¡ä¸­çš„å®ä¾‹æ•°é‡"""
        instances = 0
        if hasattr(self, 'current_batch') and self.current_batch is not None:
            if 'bboxes' in self.current_batch:
                bboxes = self.current_batch['bboxes']
                if isinstance(bboxes, list):
                    instances = sum(len(b) for b in bboxes if b is not None)
                elif torch.is_tensor(bboxes) and bboxes.numel() > 0:
                    instances = bboxes.shape[0]

        # å¤‡ç”¨è®¡æ•°è·å–
        if instances == 0 and hasattr(self, '_instance_counts') and hasattr(self, 'batch_i'):
            if self.batch_i in self._instance_counts:
                instances = self._instance_counts[self.batch_i]

        return instances

    def update_pbar(self, pbar, batch_idx, epoch):
        """ä½¿ç”¨YOLOv8åŸç”Ÿæ ¼å¼æ›´æ–°è¿›åº¦æ¡"""
        # è·å–GPUå†…å­˜ä¿¡æ¯ï¼ˆä»¥GBä¸ºå•ä½ï¼‰
        mem = f'{torch.cuda.memory_reserved() / 1E9:.1f}G' if torch.cuda.is_available() else 'CPU'

        # å¦‚æœæ˜¯tqdmè¿›åº¦æ¡å¯¹è±¡ï¼Œæ›´æ–°æè¿°
        if RANK in (-1, 0) and hasattr(pbar, 'set_description'):
            # ç¡®ä¿æŸå¤±é¡¹æ˜¯æ ‡é‡
            box_loss = self.loss_items[0].item() if torch.is_tensor(self.loss_items[0]) else self.loss_items[0]
            cls_loss = self.loss_items[1].item() if torch.is_tensor(self.loss_items[1]) else self.loss_items[1]
            dfl_loss = self.loss_items[2].item() if torch.is_tensor(self.loss_items[2]) else self.loss_items[2]

            # è·å–å®ä¾‹æ•°é‡å’Œå›¾åƒå¤§å°
            instances = self._get_instances_count()
            img_size = getattr(self.args, 'imgsz', 640)

            # ä½¿ç”¨ç›¸åŒçš„æ ¼å¼å­—ç¬¦ä¸²ï¼Œä½†ä¸åŒ…å«å°¾éƒ¨çš„å†’å·
            description = ("%11s" * 2 + "%11.3g" * 3 + "%11d" + "%11s") % (
                f"{epoch + 1}/{self.epochs}",
                mem,
                box_loss,
                cls_loss,
                dfl_loss,
                instances,
                f"{img_size}"
            )
            pbar.set_description(description)


    def preprocess_batch(self, batch):
        """é¢„å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼Œå¹¶è·Ÿè¸ªå®ä¾‹æ•°é‡"""
        # å¦‚æœæ‰¹æ¬¡ä¸ºç©ºï¼Œåˆ™åˆ›å»ºç©ºå­—å…¸
        if batch is None:
            return {'img': None}

        # åœ¨å¤„ç†å‰ç»Ÿè®¡å®ä¾‹æ•°
        instance_count = 0
        if 'bboxes' in batch:
            bboxes = batch['bboxes']
            if isinstance(bboxes, list):
                instance_count = sum(len(b) for b in bboxes if b is not None)
            elif torch.is_tensor(bboxes) and bboxes.numel() > 0:
                instance_count = bboxes.shape[0]

        # ä¿å­˜å½“å‰æ‰¹æ¬¡çš„å®ä¾‹æ•°é‡
        if not hasattr(self, '_instance_counts'):
            self._instance_counts = {}
        self._instance_counts[self.batch_i] = instance_count

        # ä¿å­˜å½“å‰æ‰¹æ¬¡å¼•ç”¨
        self.current_batch = batch

        # å°†å›¾åƒç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼Œå¹¶ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        if 'img' in batch:
            # æ£€æŸ¥å›¾åƒæ•°æ®ç±»å‹å¹¶è¿›è¡Œå¿…è¦çš„è½¬æ¢
            img = batch['img']

            # å¦‚æœå›¾åƒæ˜¯æµ®ç‚¹å‹ï¼Œç¡®ä¿å·²ç»å½’ä¸€åŒ–
            if img.dtype == torch.float32:
                # ç¡®ä¿æ•°å€¼èŒƒå›´åœ¨[0,1]
                if img.max() > 1.0:
                    img = img / 255.0
            # å¦‚æœå›¾åƒæ˜¯æ•´å‹ï¼Œè½¬æ¢ä¸ºæµ®ç‚¹å‹å¹¶å½’ä¸€åŒ–
            elif img.dtype == torch.uint8:
                img = img.float() / 255.0

            # å°†å¤„ç†åçš„å›¾åƒç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            batch['img'] = img.to(self.device, non_blocking=True)

        # ç¡®ä¿æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å…ƒç´ éƒ½åœ¨ç›¸åŒè®¾å¤‡ä¸Š
        for k in batch:
            if k != 'img' and torch.is_tensor(batch[k]):
                batch[k] = batch[k].to(self.device, non_blocking=True)

        # ç‰¹åˆ«å¤„ç†batch_idxï¼Œç¡®ä¿å®ƒå­˜åœ¨ä¸”åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if 'batch_idx' not in batch and 'cls' in batch and 'bboxes' in batch:
            # è®¡ç®—æ¯ä¸ªæ ‡ç­¾å¯¹åº”çš„æ‰¹æ¬¡ç´¢å¼•
            cls_tensor = batch['cls']
            if len(cls_tensor.shape) == 1:
                num_labels = cls_tensor.shape[0]
            else:
                num_labels = cls_tensor.shape[0] * cls_tensor.shape[1]

            # åˆ›å»ºæ‰¹æ¬¡ç´¢å¼•å¼ é‡
            if num_labels > 0:
                # å¦‚æœæ ‡ç­¾ä¸ä¸ºç©ºï¼Œä¸ºæ¯ä¸ªæ ‡ç­¾åˆ†é…æ‰¹æ¬¡ç´¢å¼•
                # å‡è®¾æ¯ä¸ªå›¾åƒæœ‰ç›¸åŒæ•°é‡çš„æ ‡ç­¾
                batch_size = batch['img'].shape[0]
                labels_per_image = num_labels // batch_size
                batch['batch_idx'] = torch.arange(batch_size, device=self.device).repeat_interleave(labels_per_image)
            else:
                # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œåˆ›å»ºç©ºå¼ é‡
                batch['batch_idx'] = torch.tensor([], device=self.device)

        return batch

    def save_model(self):
        """ä¿å­˜æ¨¡å‹ï¼Œä¿®å¤Noneç±»å‹çš„fitness_valueæ¯”è¾ƒé—®é¢˜"""
        try:
            # è®°å½•å½“å‰ç›®å½•
            current_dir = self.save_dir

            # ç¡®ä¿ä½¿ç”¨åŸå§‹ç›®å½•
            if self.original_save_dir:
                self.save_dir = self.original_save_dir

            # ç¡®ä¿weightså­ç›®å½•å­˜åœ¨
            weights_dir = Path(self.save_dir) / 'weights'
            weights_dir.mkdir(exist_ok=True)

            # ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨
            self.create_empty_results_csv()

            # è·å–éå¹¶è¡Œç‰ˆæœ¬çš„æ¨¡å‹
            from ultralytics.utils.torch_utils import de_parallel
            model = de_parallel(self.model)

            # åˆ›å»ºåŸºæœ¬æ£€æŸ¥ç‚¹å­—å…¸
            ckpt = {
                'epoch': self.epoch,
                'best_fitness': self.best_fitness,
                'model': model.state_dict(),
                'optimizer': self.optimizer.state_dict(),
                'ema': None if not hasattr(self, 'ema') or self.ema is None else self.ema.ema.state_dict(),
                'updates': None if not hasattr(self, 'ema') or self.ema is None else self.ema.updates,
                'opt': vars(self.args),
                'date': datetime.now().isoformat()
            }

            # 1. ä¿å­˜æœ€åä¸€ä¸ªepochçš„æ¨¡å‹ (last.pt) - ä»…ä¿å­˜åˆ°weightså­ç›®å½•
            last_path = str(weights_dir / 'last.pt')
            torch.save(ckpt, last_path)
            LOGGER.info(f"Saved last model to {last_path}")

            # 2. è·å–å½“å‰fitnesså€¼ï¼Œå¤„ç†Noneæƒ…å†µ
            fitness_value = None
            if hasattr(self, 'fitness') and self.fitness is not None:
                fitness_value = self.fitness
            elif hasattr(self, 'metrics') and isinstance(self.metrics, dict):
                fitness_value = self.metrics.get('fitness', None)
            elif self.metrics is not None:
                fitness_dict = getattr(self.metrics, 'results_dict', {})
                fitness_value = fitness_dict.get('fitness', None)

            # æ‰“å°å½“å‰å’Œæœ€ä½³fitnesså€¼
            LOGGER.info(f"Current fitness: {fitness_value}, Best fitness: {self.best_fitness}")

            # 3. ä¿å­˜æœ€ä½³æ¨¡å‹ (best.pt) - å®‰å…¨æ¯”è¾ƒï¼Œå¤„ç†Noneæƒ…å†µ
            is_best = False

            # å¦‚æœfitness_valueä¸ºNoneï¼Œåˆ™ä¸æ˜¯æœ€ä½³æ¨¡å‹
            # å¦‚æœfitness_valueä¸æ˜¯Noneï¼Œåˆ™ä¸best_fitnessæ¯”è¾ƒ
            if fitness_value is not None and (self.best_fitness is None or fitness_value >= self.best_fitness):
                is_best = True
                self.best_fitness = fitness_value

                # ä¿å­˜best.pt - ä»…ä¿å­˜åˆ°weightså­ç›®å½•
                best_path = str(weights_dir / 'best.pt')
                torch.save(ckpt, best_path)
                LOGGER.info(f"New best model! Saved to {best_path} with fitness {self.best_fitness}")

            # 4. æ¸…ç†æ—§æ¨¡å‹æ–‡ä»¶
            # æ¸…ç†æ ¹ç›®å½•ä¸­çš„ä»»ä½•.ptæ–‡ä»¶
            for pt_file in Path(self.save_dir).glob('*.pt'):
                try:
                    pt_file.unlink()
                    LOGGER.info(f"Removed old checkpoint from root dir: {pt_file}")
                except Exception as e:
                    LOGGER.warning(f"Failed to remove {pt_file}: {e}")

            # æ¸…ç†weightsç›®å½•ä¸­çš„æ—§epochæ–‡ä»¶
            for pt_file in weights_dir.glob('epoch_*.pt'):
                try:
                    pt_file.unlink()
                    LOGGER.info(f"Removed old checkpoint: {pt_file}")
                except Exception as e:
                    LOGGER.warning(f"Failed to remove {pt_file}: {e}")

            # ä¿å­˜åˆ¤åˆ«å™¨ - ä»…å½“åŸŸé€‚åº”å¯ç”¨æ—¶
            if self.domain_adapt_enabled and self.discriminator is not None:
                discriminator = de_parallel(self.discriminator)

                # åˆ›å»ºåˆ¤åˆ«å™¨æ£€æŸ¥ç‚¹
                disc_ckpt = {
                    'epoch': self.epoch,
                    'model': discriminator.state_dict(),
                    'optimizer': self.optimizer_D.state_dict() if hasattr(self, 'optimizer_D') else None,
                    'date': datetime.now().isoformat()
                }

                # 1. ä¿å­˜æœ€åä¸€ä¸ªepochçš„åˆ¤åˆ«å™¨ (discriminator_last.pt) - ä»…ä¿å­˜åˆ°weightså­ç›®å½•
                disc_last_path = str(weights_dir / 'discriminator_last.pt')
                torch.save(disc_ckpt, disc_last_path)
                LOGGER.info(f"Saved last discriminator to {disc_last_path}")

                # 2. ä¿å­˜æœ€ä½³åˆ¤åˆ«å™¨ (discriminator_best.pt) - ä¸ä¸»æ¨¡å‹çš„bestä¿æŒä¸€è‡´
                if is_best:
                    disc_best_path = str(weights_dir / 'discriminator_best.pt')
                    torch.save(disc_ckpt, disc_best_path)
                    LOGGER.info(f"Saved best discriminator to {disc_best_path}")

                # 3. æ¸…ç†å…¶ä»–åˆ¤åˆ«å™¨æ–‡ä»¶
                for pt_file in Path(self.save_dir).glob('discriminator*.pt'):
                    try:
                        pt_file.unlink()
                        LOGGER.info(f"Removed old discriminator from root dir: {pt_file}")
                    except Exception as e:
                        LOGGER.warning(f"Failed to remove {pt_file}: {e}")

                # æ¸…ç†weightsç›®å½•ä¸­çš„æ—§epochåˆ¤åˆ«å™¨æ–‡ä»¶
                for pt_file in weights_dir.glob('discriminator_epoch*.pt'):
                    try:
                        pt_file.unlink()
                        LOGGER.info(f"Removed old discriminator checkpoint: {pt_file}")
                    except Exception as e:
                        LOGGER.warning(f"Failed to remove {pt_file}: {e}")

            # æ¢å¤ç›®å½•
            self.save_dir = current_dir

        except Exception as e:
            LOGGER.error(f"Error in save_model: {e}")
            import traceback
            LOGGER.error(traceback.format_exc())

            try:
                # ç®€åŒ–çš„ç´§æ€¥ä¿å­˜ - ä»…ä¿å­˜åˆ°weightså­ç›®å½•
                from ultralytics.utils.torch_utils import de_parallel
                model = de_parallel(self.model)

                # ç¡®ä¿weightsç›®å½•å­˜åœ¨
                weights_dir = Path(self.save_dir) / 'weights'
                weights_dir.mkdir(exist_ok=True)

                # ä»…ä¿å­˜åˆ°weightsç›®å½•
                save_path = str(weights_dir / 'last.pt')
                torch.save({'model': model.state_dict()}, save_path)
                LOGGER.info(f"Emergency save completed to {save_path}")

                # ä¿å­˜åˆ¤åˆ«å™¨ - ä»…ä¿å­˜åˆ°weightsç›®å½•
                if self.domain_adapt_enabled and self.discriminator is not None:
                    discriminator = de_parallel(self.discriminator)
                    disc_path = str(weights_dir / 'discriminator_last.pt')
                    torch.save(discriminator.state_dict(), disc_path)
                    LOGGER.info(f"Emergency discriminator save completed to {disc_path}")

            except Exception as inner_e:
                LOGGER.error(f"Emergency save failed: {inner_e}")