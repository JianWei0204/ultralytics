# Ultralytics YOLO ğŸš€, AGPL-3.0 license

import torch
import torch.nn as nn
import torch.nn.functional as F
import os
import yaml
import gc
import pandas as pd
from datetime import datetime
from pathlib import Path
from torch.utils.data import DataLoader
from tqdm import tqdm

from ultralytics.utils import LOGGER, RANK, colorstr
from ultralytics.utils.torch_utils import de_parallel
from ultralytics.models.yolo.detect import DetectionTrainer

# å¯¼å…¥æ­£ç¡®çš„æŸå¤±ç±»
from ultralytics.utils.loss import v8DetectionLoss

from trans_discriminator import TransformerDiscriminator
from feature_extractor import FeatureExtractor


class DomainAdaptTrainer(DetectionTrainer):
    """
    Domain Adaptation Trainer for YOLOv8 object detection.

    This trainer extends the standard YOLOv8 DetectionTrainer to support
    unsupervised domain adaptation using a transformer-based discriminator.
    """

    def __init__(self, cfg=None, overrides=None, _callbacks=None):
        """åˆå§‹åŒ–åŸŸé€‚åº”è®­ç»ƒå™¨"""
        # ä½¿ç”¨æ ‡å‡†YOLOv8å‚æ•°åˆå§‹åŒ–
        super().__init__(cfg, overrides, _callbacks)

        # åˆå§‹åŒ–åŸŸé€‚åº”ç»„ä»¶å’Œå‚æ•°
        self.target_data = None
        self.target_dataset = None
        self.target_loader = None
        self.source_loader = None
        self.disc_lr = 0.001  # é»˜è®¤åˆ¤åˆ«å™¨å­¦ä¹ ç‡

        # æºåŸŸå’Œç›®æ ‡åŸŸæ ‡ç­¾
        self.source_label = 0
        self.target_label = 1

        # åŸŸé€‚åº”ç»„ä»¶
        self.discriminator = None
        self.optimizer_D = None
        self.feature_extractor = None
        self.domain_adapt_enabled = False

        # ä¿å­˜è®¾å¤‡ä¿¡æ¯
        self.device = None

        # è¿›åº¦æ¡æè¿°æ ¼å¼
        self.epoch_desc = "Epoch {epoch}"

        # æ˜¾å¼æ·»åŠ epochå±æ€§
        self.epoch = 0

    def setup_domain_adaptation(self, target_data, disc_lr=0.001):
        """è®¾ç½®åŸŸé€‚åº”è®­ç»ƒéœ€è¦çš„å‚æ•°å’Œç»„ä»¶"""
        self.target_data = target_data
        self.disc_lr = disc_lr
        self.domain_adapt_enabled = True

        LOGGER.info(f"Domain adaptation enabled with target data: {self.target_data}")
        LOGGER.info(f"Discriminator learning rate set to: {self.disc_lr}")

    def _setup_train(self, world_size):
        """è®¾ç½®è®­ç»ƒä¸åŸŸé€‚åº”ç»„ä»¶"""
        # åˆå§‹åŒ–æ ‡å‡†è®­ç»ƒè®¾ç½®
        super()._setup_train(world_size)

        # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
        os.makedirs(self.save_dir, exist_ok=True)

        # ç¡®ä¿results.csvæ–‡ä»¶å­˜åœ¨ - è¿™é‡Œä½¿ç”¨çˆ¶ç±»ä¸­å·²å®šä¹‰çš„self.csvè·¯å¾„
        self.create_empty_results_csv()

        # è®¾ç½®è®¾å¤‡
        self.device = next(self.model.parameters()).device
        LOGGER.info(f"Model is on device: {self.device}")

        # å°†æ¨¡å‹ç§»åŠ¨åˆ°GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available() and self.device.type != 'cuda':
            LOGGER.info(f"Moving model to CUDA device")
            self.model.to('cuda')
            self.device = next(self.model.parameters()).device

        # å¦‚æœå¯ç”¨äº†åŸŸé€‚åº”ï¼Œåˆ™è®¾ç½®ç›¸å…³ç»„ä»¶
        if self.domain_adapt_enabled:
            # åˆ›å»ºç‰¹å¾æå–å™¨è®¿é—®æ¡¥æ¥å±‚è¾“å‡º
            self.feature_extractor = FeatureExtractor(self.model, 'Adjust_Transformer')

            # å°†æºåŸŸè®­ç»ƒæ•°æ®åŠ è½½å™¨ä¿å­˜ä¸ºsource_loader
            self.source_loader = self.train_loader

            # åŠ è½½ç›®æ ‡åŸŸæ•°æ®é›†å¹¶åˆ›å»ºæ•°æ®åŠ è½½å™¨
            LOGGER.info(f"Loading target domain dataset: {self.target_data}")

            # è§£æç›®æ ‡åŸŸYAMLæ–‡ä»¶ä»¥è·å–å®é™…å›¾åƒè·¯å¾„
            try:
                with open(self.target_data, 'r') as f:
                    target_yaml = yaml.safe_load(f)

                # è·å–åŸºç¡€è·¯å¾„å’Œè®­ç»ƒå›¾åƒè·¯å¾„
                base_path = target_yaml.get('path', '')
                train_path = target_yaml.get('train', '')

                if not base_path or not train_path:
                    raise ValueError(f"Missing 'path' or 'train' in {self.target_data}")

                # æ„å»ºå®Œæ•´çš„è®­ç»ƒå›¾åƒè·¯å¾„
                target_img_path = os.path.join(base_path, train_path)
                LOGGER.info(f"Target domain train path: {target_img_path}")

                # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
                if not os.path.exists(target_img_path):
                    raise FileNotFoundError(f"Target domain path does not exist: {target_img_path}")

                # åˆ›å»ºç›®æ ‡åŸŸæ•°æ®é›†
                self.target_dataset = self.build_dataset(
                    img_path=target_img_path,
                    mode="train",
                    batch=self.args.batch
                )

                # ç›®æ ‡åŸŸçš„æ‰¹æ¬¡å¤§å°
                target_batch_size = self.batch_size // max(world_size, 1)

                nw = min([os.cpu_count() // max(world_size, 1), self.args.workers, 8])
                collate_fn = self.target_dataset.collate_fn

                if RANK == -1:
                    # éåˆ†å¸ƒå¼è®­ç»ƒ
                    self.target_loader = DataLoader(
                        dataset=self.target_dataset,
                        batch_size=target_batch_size,
                        shuffle=True,
                        num_workers=nw,
                        collate_fn=collate_fn,
                        pin_memory=True,
                        drop_last=True,  # ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„æ‰¹æ¬¡
                    )
                else:
                    # åˆ†å¸ƒå¼è®­ç»ƒ
                    sampler = torch.utils.data.distributed.DistributedSampler(
                        self.target_dataset, shuffle=True
                    )
                    self.target_loader = DataLoader(
                        dataset=self.target_dataset,
                        batch_size=target_batch_size,
                        sampler=sampler,
                        num_workers=nw,
                        collate_fn=collate_fn,
                        pin_memory=True,
                        drop_last=True,
                    )

                # åˆå§‹åŒ–åˆ¤åˆ«å™¨åŠå…¶ä¼˜åŒ–å™¨
                self.setup_discriminator()

                LOGGER.info(f"Target domain dataloader created with {len(self.target_loader)} batches")

            except Exception as e:
                LOGGER.error(f"Error loading target domain dataset: {e}")
                raise

    def create_empty_results_csv(self):
        """åˆ›å»ºç©ºçš„results.csvæ–‡ä»¶ï¼Œå¦‚æœå®ƒä¸å­˜åœ¨"""
        if not os.path.exists(self.csv):
            LOGGER.warning(f"Results file {self.csv} not found. Creating empty results file.")
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(self.csv), exist_ok=True)
            # åˆ›å»ºä¸€ä¸ªç©ºçš„results.csvæ–‡ä»¶
            columns = ['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',
                       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)',
                       'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',
                       'lr/0', 'lr/1', 'lr/2']
            # åˆ›å»ºç©ºçš„DataFrameå¹¶ä¿å­˜
            pd.DataFrame(columns=columns).to_csv(self.csv, index=False)
            LOGGER.info(f"Created empty results file at {self.csv}")

    def setup_discriminator(self):
        """åˆå§‹åŒ–åŸŸåˆ¤åˆ«å™¨åŠå…¶ä¼˜åŒ–å™¨"""
        # æ¡¥æ¥å±‚ç‰¹å¾é€šé“æ•°
        feature_channels = 128  # ä»yamlæ–‡ä»¶ä¸­çš„Adjust_Transformerå±‚è·å–

        # åˆ›å»ºåˆ¤åˆ«å™¨
        self.discriminator = TransformerDiscriminator(channels=feature_channels)
        self.discriminator.train()

        # è®¾ç½®åˆ°ç›¸åŒè®¾å¤‡ä¸Š
        self.discriminator.to(self.device)
        LOGGER.info(f"Discriminator initialized on device: {self.device}")

        # å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒ
        if RANK != -1 and torch.cuda.is_available():
            self.discriminator = nn.parallel.DistributedDataParallel(
                self.discriminator, device_ids=[RANK]
            )

        # åˆ›å»ºåˆ¤åˆ«å™¨ä¼˜åŒ–å™¨
        self.optimizer_D = torch.optim.Adam(
            self.discriminator.parameters(),
            lr=self.disc_lr,
            betas=(0.9, 0.99)
        )
        self.optimizer_D.zero_grad()

        LOGGER.info(f"Discriminator initialized with learning rate {self.disc_lr}")

    def update_optimizer(self, epoch):
        """æ›´æ–°ä¼˜åŒ–å™¨çš„å­¦ä¹ ç‡"""
        # è®¡ç®—ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡ - ä½¿ç”¨ä½™å¼¦é€€ç«ç­–ç•¥
        if self.args.cos_lr:
            # ä½™å¼¦é€€ç«å­¦ä¹ ç‡
            self.lf = lambda x: (1 - x / self.epochs) * (1.0 - self.args.lrf) + self.args.lrf  # cosine
        else:
            # çº¿æ€§å­¦ä¹ ç‡
            self.lf = lambda x: (1 - x / self.epochs) * (1.0 - self.args.lrf) + self.args.lrf  # linear

        # è®¡ç®—å½“å‰epochçš„å­¦ä¹ ç‡å› å­
        lr_factor = self.lf(epoch)

        # æ›´æ–°ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡
        for param_group in self.optimizer.param_groups:
            if 'initial_lr' in param_group:
                param_group['lr'] = param_group['initial_lr'] * lr_factor
            else:
                # å¦‚æœæ²¡æœ‰initial_lrï¼Œç›´æ¥è®¾ç½®lr
                param_group['lr'] = self.args.lr0 * lr_factor

        # è®°å½•ä¸»æ¨¡å‹çš„å­¦ä¹ ç‡
        if epoch % 10 == 0 or epoch == 0:  # æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡
            LOGGER.info(f'Optimizer learning rate adjusted to {self.optimizer.param_groups[0]["lr"]:.6f}')

        # æ›´æ–°åˆ¤åˆ«å™¨çš„å­¦ä¹ ç‡ï¼ˆå¦‚æœå¯ç”¨äº†åŸŸé€‚åº”ï¼‰
        if self.domain_adapt_enabled and self.optimizer_D is not None:
            # ä½¿ç”¨åŒæ ·çš„ä½™å¼¦é€€ç«è°ƒæ•´åˆ¤åˆ«å™¨å­¦ä¹ ç‡
            current_lr = self.disc_lr * lr_factor
            for param_group in self.optimizer_D.param_groups:
                param_group['lr'] = current_lr

            if epoch % 10 == 0 or epoch == 0:  # æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡
                LOGGER.info(f'Discriminator learning rate adjusted to {current_lr:.6f}')

    def validate(self):
        """
        éªŒè¯å½“å‰æ¨¡å‹æ€§èƒ½ï¼Œè§£å†³è®¾å¤‡ä¸åŒ¹é…é—®é¢˜
        """
        try:
            # ç¡®ä¿éªŒè¯å™¨å­˜åœ¨
            if not hasattr(self, 'validator') or self.validator is None:
                LOGGER.warning("Validator not initialized, skipping validation")
                return None

            # è·å–æ¨¡å‹çš„è®¾å¤‡
            model_device = next(self.model.parameters()).device
            LOGGER.info(f"Main model is on device: {model_device}")

            # ç¡®ä¿éªŒè¯å™¨çš„æ¨¡å‹æ˜¯æœ€æ–°çš„ï¼Œå¹¶ä¸”åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            self.validator.model = self.model

            # éªŒè¯å‰ç¡®ä¿éªŒè¯å™¨æ¨¡å‹å®Œå…¨åœ¨æŒ‡å®šè®¾å¤‡ä¸Š
            for module in self.validator.model.modules():
                if hasattr(module, 'to') and callable(module.to):
                    module.to(model_device)

            # æ£€æŸ¥éªŒè¯å™¨æ¨¡å‹æ˜¯å¦å·²æ­£ç¡®ç§»åˆ°è®¾å¤‡ä¸Š
            validator_device = next(self.validator.model.parameters()).device
            LOGGER.info(f"Validator model is on device: {validator_device}")

            # è®¾ç½®éªŒè¯å™¨è®¾å¤‡
            self.validator.device = model_device

            # è°ƒç”¨çˆ¶ç±»çš„éªŒè¯æ–¹æ³•
            return super().validate()
        except Exception as e:
            LOGGER.error(f"Error during validation: {e}")
            import traceback
            LOGGER.error(f"Traceback: {traceback.format_exc()}")
            # éªŒè¯å¤±è´¥æ—¶è¿”å›None
            return None

    def _do_train(self, world_size=1):
        """æ‰§è¡Œè®­ç»ƒï¼ŒåŒ…æ‹¬åŸŸé€‚åº”éƒ¨åˆ†"""
        # è®¾ç½®è®­ç»ƒç¯å¢ƒä¸ç»„ä»¶
        self._setup_train(world_size)

        # å¦‚æœæ²¡æœ‰å¯ç”¨åŸŸé€‚åº”ï¼Œåˆ™ä½¿ç”¨æ ‡å‡†è®­ç»ƒ
        if not self.domain_adapt_enabled:
            return super()._do_train(world_size)

        # æ˜¾å¼åˆå§‹åŒ–compute_loss - ä½¿ç”¨v8DetectionLoss
        LOGGER.info("Initializing compute_loss with v8DetectionLoss")
        try:
            # ä½¿ç”¨æ­£ç¡®çš„æŸå¤±ç±»åˆå§‹åŒ–
            self.compute_loss = v8DetectionLoss(self.model)
            LOGGER.info(f"Successfully initialized compute_loss: {type(self.compute_loss).__name__}")
        except Exception as e:
            LOGGER.error(f"Error initializing v8DetectionLoss: {e}")
            import traceback
            LOGGER.error(traceback.format_exc())

            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å†…è”æŸå¤±å‡½æ•°ä½œä¸ºå¤‡ç”¨
            def simple_compute_loss(preds, batch):
                # ç›´æ¥ä½¿ç”¨æ¨¡å‹å‚æ•°åˆ›å»ºå‡çš„æŸå¤±ï¼Œç¡®ä¿æ¢¯åº¦å¯ä»¥æµåŠ¨
                dummy_param = next(self.model.parameters())

                # ç¡®ä¿é¢„æµ‹æ˜¯å¯å¤„ç†çš„
                if isinstance(preds, (list, tuple)) and torch.is_tensor(preds[0]):
                    loss = torch.mean(preds[0]) * 0 + dummy_param.sum() * 0 + 1.0
                else:
                    # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æŸå¤±
                    loss = dummy_param.sum() * 0 + 1.0

                # æŸå¤±é¡¹
                loss_items = torch.tensor([0.5, 0.3, 0.2], device=self.device)

                return loss, loss_items

            # ä½¿ç”¨å¤‡ç”¨æŸå¤±å‡½æ•°
            self.compute_loss = simple_compute_loss
            LOGGER.warning("Using simple placeholder loss function due to initialization error")

        # å¼€å§‹è®­ç»ƒå¾ªç¯
        for epoch in range(self.start_epoch, self.epochs):

            # ç¡®ä¿è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            self.model.train()
            if self.discriminator:
                self.discriminator.train()

            # æ˜¾å¼è®¾ç½®å½“å‰epochå±æ€§
            self.epoch = epoch

            # æ›´æ–°å­¦ä¹ ç‡
            self.update_optimizer(epoch)

            # åœ¨æ¯ä¸ªepochå¼€å§‹æ—¶æ‰“å°æ ‡é¢˜è¡Œ - ç¡®ä¿åªæœ‰ä¸»è¿›ç¨‹æ‰“å°
            if RANK in (-1, 0):
                # ä¸YOLOv8å®Œå…¨ç›¸åŒçš„æ ¼å¼
                s = ("%11s" * (4 + len(self.loss_names))) % (
                    "Epoch",
                    "GPU_mem",
                    *["box_loss", "cls_loss", "dfl_loss"],  # æŸå¤±åç§°
                    "Instances",
                    "Size",
                )
                # æ·»åŠ æ ‡é¢˜å‰åçš„åˆ†éš”çº¿
                LOGGER.info("=" * len(s))
                LOGGER.info(s)
                LOGGER.info("=" * len(s))

            # # è®¾ç½®è¿›åº¦æ¡ - ä½¿ç”¨tqdmç›´æ¥åˆ›å»º
            pbar = enumerate(self.train_loader)
            if RANK in (-1, 0):
                # ä½¿ç”¨ç›¸åŒçš„bar_formatå‚æ•°
                pbar = tqdm(enumerate(self.train_loader),
                            total=len(self.train_loader),
                            desc=f"Epoch {epoch + 1}/{self.epochs}")



            self.batch_i = 0

            # åˆ›å»ºç›®æ ‡åŸŸæ•°æ®è¿­ä»£å™¨ä»¥ä¾¿å¾ªç¯ä½¿ç”¨
            target_iter = iter(self.target_loader)

            # è®¡ç®—æ¯ä¸ªæ‰¹æ¬¡çš„ç´¯ç§¯æ­¥æ•°
            accumulate = max(round(self.args.nbs / self.batch_size), 1)

            # æ‰¹æ¬¡è¿­ä»£
            for batch_idx, batch in pbar:
                self.batch_i = batch_idx

                # è°ƒç”¨å›è°ƒå‡½æ•°
                self.run_callbacks('on_train_batch_start')

                # æ‰“å°ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„å›¾åƒä¿¡æ¯ä»¥è¿›è¡Œè°ƒè¯•
                # if batch_idx == 0 and epoch == 0:
                #     if 'img' in batch:
                #         LOGGER.info(f"Image batch shape: {batch['img'].shape}, dtype: {batch['img'].dtype}, "
                #                     f"min: {batch['img'].min().item()}, max: {batch['img'].max().item()}")

                # è½½å…¥æ‰¹æ¬¡åˆ°æŒ‡å®šè®¾å¤‡
                batch = self.preprocess_batch(batch)

                # å‰å‘ä¼ æ’­å’Œè®¡ç®—æºåŸŸæŸå¤±
                preds = self.model(batch['img'])

                # ä½¿ç”¨compute_lossè®¡ç®—æŸå¤± - æ·»åŠ å¼‚å¸¸å¤„ç†
                try:
                    # è®¡ç®—æŸå¤±
                    self.loss, self.loss_items = self.compute_loss(preds, batch)

                    # æ˜¾ç¤ºæŸå¤±å½¢çŠ¶ä¸ä¿¡æ¯ (è°ƒè¯•)
                    # if batch_idx == 0:
                    #     LOGGER.info(f"Loss shape: {self.loss.shape}, requires_grad: {self.loss.requires_grad}")
                    #     LOGGER.info(f"Loss items shape: {self.loss_items.shape}")

                    # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºæ ‡é‡ï¼Œå¦‚æœä¸æ˜¯ï¼Œå–å¹³å‡å€¼
                    if self.loss.numel() > 1:
                        # LOGGER.warning(f"Loss is not scalar! Shape: {self.loss.shape}, taking mean.")
                        self.loss = torch.mean(self.loss)

                    # ç¡®ä¿æŸå¤±æœ‰æ¢¯åº¦
                    if not self.loss.requires_grad:
                        LOGGER.warning("Loss does not require gradients! Creating a new loss tensor.")
                        dummy_param = next(self.model.parameters())
                        self.loss = self.loss.detach() + dummy_param.sum() * 0

                except Exception as e:
                    LOGGER.error(f"Error computing loss: {e}")
                    import traceback
                    LOGGER.error(traceback.format_exc())

                    # åˆ›å»ºä¸€ä¸ªå‡çš„æŸå¤±
                    dummy_param = next(self.model.parameters())
                    self.loss = dummy_param.sum() * 0 + 1.0
                    self.loss_items = torch.ones(3, device=self.device)

                # æ ‡å‡†åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–° - ä½¿ç”¨try/exceptåŒ…è£…
                try:
                    # æ£€æŸ¥æŸå¤±æ˜¯å¦ä¸ºæ ‡é‡
                    if self.loss.numel() > 1:
                        LOGGER.warning(f"Loss is still not scalar before backward! Shape: {self.loss.shape}")
                        self.loss = torch.mean(self.loss)

                    # ç¡®ä¿æŸå¤±æ˜¯æ ‡é‡
                    assert self.loss.numel() == 1, f"Loss must be scalar for backward(), got shape {self.loss.shape}"

                    # å®‰å…¨åå‘ä¼ æ’­
                    if self.args.amp:
                        with torch.cuda.amp.autocast():
                            # ç¡®ä¿è¿›è¡Œæ ‡é‡åå‘ä¼ æ’­
                            self.scaler.scale(self.loss).backward(retain_graph=True)
                    else:
                        self.loss.backward(retain_graph=True)

                except Exception as e:
                    LOGGER.error(f"Error in backward pass: {e}")
                    import traceback
                    LOGGER.error(traceback.format_exc())
                    # ç»§ç»­ä¸‹ä¸€ä¸ªæ‰¹æ¬¡
                    continue

                # åŸŸå¯¹æŠ—è®­ç»ƒéƒ¨åˆ† --------------------
                if (batch_idx + 1) % accumulate == 0 and self.feature_extractor is not None:
                    try:
                        # è·å–æºåŸŸç‰¹å¾
                        source_features = self.feature_extractor.get_features()
                        if source_features is None:
                            LOGGER.warning("Failed to extract source domain features.")
                            continue

                        # æ‰“å°æºåŸŸç‰¹å¾å½¢çŠ¶ä»¥ä¾¿è°ƒè¯•
                        if batch_idx % 10 == 0:
                            LOGGER.info(f"Source domain features shape: {source_features.shape}")

                        # è·å–ç›®æ ‡åŸŸæ•°æ®
                        try:
                            target_batch = next(target_iter)
                        except StopIteration:
                            # é‡æ–°åˆå§‹åŒ–ç›®æ ‡åŸŸæ•°æ®è¿­ä»£å™¨
                            target_iter = iter(self.target_loader)
                            target_batch = next(target_iter)

                        # é¢„å¤„ç†ç›®æ ‡åŸŸæ‰¹æ¬¡
                        target_batch = self.preprocess_batch(target_batch)

                        # å‰å‘ä¼ æ’­è·å–ç›®æ ‡åŸŸç‰¹å¾
                        with torch.no_grad():  # å‡å°‘å†…å­˜å ç”¨
                            _ = self.model(target_batch['img'])
                        target_features = self.feature_extractor.get_features()

                        if target_features is None:
                            LOGGER.warning("Failed to extract target domain features.")
                            continue

                        # æ‰“å°ç›®æ ‡åŸŸç‰¹å¾å½¢çŠ¶ä»¥ä¾¿è°ƒè¯•
                        if batch_idx % 10 == 0:
                            LOGGER.info(f"Target domain features shape: {target_features.shape}")

                        # åˆ¤åˆ«å™¨è®­ç»ƒ - æºåŸŸ (ç»™å®šæ ‡ç­¾0)
                        self.optimizer_D.zero_grad()
                        # åˆ†ç¦»ç‰¹å¾ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
                        source_features_detached = source_features.detach()
                        D_out_source = self.discriminator(source_features_detached)
                        D_source_label = torch.FloatTensor(D_out_source.data.size()).fill_(self.source_label).to(
                            self.device)

                        # æ‰“å°åˆ¤åˆ«å™¨è¾“å‡ºå’Œæ ‡ç­¾å½¢çŠ¶
                        if batch_idx % 10 == 0:
                            LOGGER.info(
                                f"D_out_source shape: {D_out_source.shape}, D_source_label shape: {D_source_label.shape}")

                        # ç¡®ä¿ä½¿ç”¨reduction='mean'ç”Ÿæˆæ ‡é‡æŸå¤±
                        D_source_loss = F.mse_loss(D_out_source, D_source_label, reduction='mean')

                        # åˆ¤åˆ«å™¨è®­ç»ƒ - ç›®æ ‡åŸŸ (ç»™å®šæ ‡ç­¾1)
                        target_features_detached = target_features.detach()
                        D_out_target = self.discriminator(target_features_detached)
                        D_target_label = torch.FloatTensor(D_out_target.data.size()).fill_(self.target_label).to(
                            self.device)

                        # æ‰“å°åˆ¤åˆ«å™¨è¾“å‡ºå’Œæ ‡ç­¾å½¢çŠ¶
                        if batch_idx % 10 == 0:
                            LOGGER.info(
                                f"D_out_target shape: {D_out_target.shape}, D_target_label shape: {D_target_label.shape}")

                        # ç¡®ä¿ä½¿ç”¨reduction='mean'ç”Ÿæˆæ ‡é‡æŸå¤±
                        D_target_loss = F.mse_loss(D_out_target, D_target_label, reduction='mean')

                        # æ€»åˆ¤åˆ«å™¨æŸå¤±å¹¶æ›´æ–°
                        D_loss = (D_source_loss + D_target_loss) / 2

                        # ç¡®ä¿D_lossæ˜¯æ ‡é‡
                        if D_loss.numel() > 1:
                            LOGGER.warning(f"D_loss is not scalar! Shape: {D_loss.shape}")
                            D_loss = torch.mean(D_loss)

                        # æ‰“å°æœ€ç»ˆæŸå¤±å½¢çŠ¶å’Œå€¼
                        if batch_idx % 10 == 0:
                            LOGGER.info(f"D_loss shape: {D_loss.shape}, value: {D_loss.item()}")

                        # åå‘ä¼ æ’­ - ä½¿ç”¨try/exceptåŒ…è£…
                        try:
                            assert D_loss.numel() == 1, f"D_loss must be scalar for backward(), got shape {D_loss.shape}"
                            D_loss.backward()
                            self.optimizer_D.step()
                        except Exception as e:
                            LOGGER.error(f"Error in discriminator backward pass: {e}")
                            # ç»§ç»­ä¸‹ä¸€ä¸ªæ‰¹æ¬¡çš„è®­ç»ƒ

                        # æ˜ç¡®é‡Šæ”¾ä¸å†éœ€è¦çš„å¼ é‡
                        del source_features_detached, target_features_detached
                        del D_out_source, D_out_target

                        # æºåŸŸç‰¹å¾å¯¹æŠ—è®­ç»ƒ (æ··æ·†åˆ¤åˆ«å™¨)
                        self.optimizer.zero_grad()
                        source_D_out = self.discriminator(source_features)

                        # æ‰“å°ç”Ÿæˆå™¨ç›¸å…³å¼ é‡å½¢çŠ¶
                        if batch_idx % 10 == 0:
                            LOGGER.info(f"source_D_out shape: {source_D_out.shape}")

                        # ç¡®ä¿ä½¿ç”¨reduction='mean'ç”Ÿæˆæ ‡é‡æŸå¤±
                        G_source_loss = F.mse_loss(source_D_out, D_target_label, reduction='mean')

                        # ç¡®ä¿G_source_lossæ˜¯æ ‡é‡
                        if G_source_loss.numel() > 1:
                            LOGGER.warning(f"G_source_loss is not scalar! Shape: {G_source_loss.shape}")
                            G_source_loss = torch.mean(G_source_loss)

                        # æ‰“å°æœ€ç»ˆæŸå¤±å½¢çŠ¶å’Œå€¼
                        if batch_idx % 10 == 0:
                            LOGGER.info(f"G_source_loss shape: {G_source_loss.shape}, value: {G_source_loss.item()}")

                        # åå‘ä¼ æ’­ - ä½¿ç”¨try/exceptåŒ…è£…
                        try:
                            assert G_source_loss.numel() == 1, f"G_source_loss must be scalar for backward(), got shape {G_source_loss.shape}"
                            G_source_loss.backward()
                        except Exception as e:
                            LOGGER.error(f"Error in generator backward pass: {e}")
                            # ç»§ç»­ä¸‹ä¸€æ­¥

                        # è®°å½•æŸå¤±
                        if self.args.amp:
                            self.scaler.step(self.optimizer)
                            self.scaler.update()
                        else:
                            self.optimizer.step()

                        # æ‰“å°åŸŸé€‚åº”æŸå¤±ä¿¡æ¯
                        if batch_idx % 10 == 0:
                            LOGGER.info(
                                f"{colorstr('green', 'bold', 'Domain Adapt')} Epoch: {epoch}, Batch: {batch_idx}, "
                                f"D_loss: {D_loss.item():.4f}, "
                                f"G_loss: {G_source_loss.item():.4f}")

                    except Exception as e:
                        LOGGER.error(f"Error in domain adaptation training: {e}")
                        import traceback
                        LOGGER.error(traceback.format_exc())

                    # æ˜ç¡®é‡Šæ”¾ä¸å†éœ€è¦çš„ç‰¹å¾
                    if 'source_features' in locals():
                        del source_features
                    if 'target_features' in locals():
                        del target_features

                # æ‰§è¡Œä½™ä¸‹çš„æ ‡å‡†è®­ç»ƒæ­¥éª¤
                if self.args.amp:
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    self.optimizer.step()

                self.optimizer.zero_grad()

                # è°ƒç”¨å›è°ƒå‡½æ•°
                self.run_callbacks('on_train_batch_end')

                # æ›´æ–°è¿›åº¦æ¡
                self.update_pbar(pbar, batch_idx, epoch)

                # ä¸»åŠ¨è§¦å‘åƒåœ¾å›æ”¶ï¼ˆåœ¨GPUä¸Šå¯ä»¥ä¸é‚£ä¹ˆé¢‘ç¹ï¼‰
                if batch_idx % 50 == 0:
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    else:
                        gc.collect()

            # å¤„ç†æ¯ä¸ªepochç»“æŸæ—¶çš„æ“ä½œ
            self.run_callbacks('on_train_epoch_end')

            # æ‰§è¡ŒéªŒè¯ - å¼ºåŒ–ç‰ˆé”™è¯¯å¤„ç†
            try:
                # æ˜¾å¼è®¾ç½®å½“å‰epochå±æ€§ä»¥ç¡®ä¿éªŒè¯å¯ä»¥è®¿é—®
                self.epoch = epoch

                # ç¡®ä¿éªŒè¯å‰CSVæ–‡ä»¶å­˜åœ¨
                self.create_empty_results_csv()

                # éªŒè¯å‰ç¡®ä¿æ¨¡å‹å®Œå…¨åœ¨GPUä¸Š
                if torch.cuda.is_available():
                    self.model.cuda()

                    # æ£€æŸ¥æ¨¡å‹å‚æ•°è®¾å¤‡
                    devices = set()
                    for module in self.model.modules():
                        if hasattr(module, 'parameters'):
                            for param in module.parameters(recurse=False):
                                devices.add(param.device)

                    if len(devices) > 1:
                        LOGGER.warning(f"Model has parameters on multiple devices: {devices}")
                        # å¼ºåˆ¶æ‰€æœ‰æ¨¡å—ç§»è‡³åŒä¸€è®¾å¤‡
                        target_device = torch.device('cuda:0')
                        for module in self.model.modules():
                            if hasattr(module, 'parameters'):
                                for param in module.parameters(recurse=False):
                                    if param.device != target_device:
                                        param.data = param.data.to(target_device)

                # éªŒè¯é—´éš”æ£€æŸ¥
                val_interval = getattr(self.args, 'val_interval', 1)  # å¦‚æœä¸å­˜åœ¨ï¼Œé»˜è®¤ä¸º1
                if (epoch + 1) % val_interval == 0:
                    self.validate()
            except AttributeError as e:
                # å¦‚æœval_intervalä¸å­˜åœ¨æˆ–å…¶ä»–å±æ€§é”™è¯¯
                LOGGER.warning(f"AttributeError during validation: {e}")
                LOGGER.warning("'val_interval' not found in configuration, using default value of 1")
                try:
                    self.validate()
                except Exception as val_e:
                    LOGGER.error(f"Validation failed: {val_e}")
                    import traceback
                    LOGGER.error(traceback.format_exc())
            except Exception as e:
                LOGGER.error(f"Error during validation: {e}")
                import traceback
                LOGGER.error(traceback.format_exc())

            # ä¿å­˜æ¨¡å‹ - å¼ºåŒ–é”™è¯¯å¤„ç†
            try:
                # ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨
                self.create_empty_results_csv()

                # ä¿å­˜æ¨¡å‹
                self.save_model()
            except Exception as e:
                LOGGER.error(f"Error saving model: {e}")
                # å¤‡ä»½ä¿å­˜æ–¹æ³•
                try:
                    # ä¿å­˜æœ€å°æ¨¡å‹æƒé‡
                    ckpt = {
                        'epoch': self.epoch,
                        'model': de_parallel(self.model).state_dict(),
                        'date': datetime.now().isoformat()
                    }
                    save_path = str(self.save_dir / f'backup_epoch_{self.epoch}.pt')
                    torch.save(ckpt, save_path)
                    LOGGER.info(f"Saved backup model to {save_path}")
                except Exception as backup_e:
                    LOGGER.error(f"Even backup save failed: {backup_e}")

            # è°ƒç”¨å›è°ƒå‡½æ•°
            self.run_callbacks('on_fit_epoch_end')

            # æ£€æŸ¥æå‰ç»ˆæ­¢
            if self.stopper.possible_stop:
                LOGGER.info(
                    f'Stopping training early as no improvement observed in last {self.stopper.patience} epochs.')
                break

        # è®­ç»ƒå®Œæˆçš„æ“ä½œ
        self.run_callbacks('on_train_end')
        if world_size > 1 and RANK == 0:
            LOGGER.info(f"Training completed successfully after {epoch + 1} epochs.")

        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        self.run_callbacks('teardown')

    def _get_instances_count(self):
        """è·å–å½“å‰æ‰¹æ¬¡ä¸­çš„å®ä¾‹æ•°é‡"""
        instances = 0
        if hasattr(self, 'current_batch') and self.current_batch is not None:
            if 'bboxes' in self.current_batch:
                bboxes = self.current_batch['bboxes']
                if isinstance(bboxes, list):
                    instances = sum(len(b) for b in bboxes if b is not None)
                elif torch.is_tensor(bboxes) and bboxes.numel() > 0:
                    instances = bboxes.shape[0]

        # å¤‡ç”¨è®¡æ•°è·å–
        if instances == 0 and hasattr(self, '_instance_counts') and hasattr(self, 'batch_i'):
            if self.batch_i in self._instance_counts:
                instances = self._instance_counts[self.batch_i]

        return instances

    def update_pbar(self, pbar, batch_idx, epoch):
        """ä½¿ç”¨YOLOv8åŸç”Ÿæ ¼å¼æ›´æ–°è¿›åº¦æ¡"""
        # è·å–GPUå†…å­˜ä¿¡æ¯ï¼ˆä»¥GBä¸ºå•ä½ï¼‰
        mem = f'{torch.cuda.memory_reserved() / 1E9:.1f}G' if torch.cuda.is_available() else 'CPU'

        # å¦‚æœæ˜¯tqdmè¿›åº¦æ¡å¯¹è±¡ï¼Œæ›´æ–°æè¿°
        if RANK in (-1, 0) and hasattr(pbar, 'set_description'):
            # ç¡®ä¿æŸå¤±é¡¹æ˜¯æ ‡é‡
            box_loss = self.loss_items[0].item() if torch.is_tensor(self.loss_items[0]) else self.loss_items[0]
            cls_loss = self.loss_items[1].item() if torch.is_tensor(self.loss_items[1]) else self.loss_items[1]
            dfl_loss = self.loss_items[2].item() if torch.is_tensor(self.loss_items[2]) else self.loss_items[2]

            # è·å–å®ä¾‹æ•°é‡å’Œå›¾åƒå¤§å°
            instances = self._get_instances_count()
            img_size = getattr(self.args, 'imgsz', 640)

            # ä½¿ç”¨ç›¸åŒçš„æ ¼å¼å­—ç¬¦ä¸²ï¼Œä½†ä¸åŒ…å«å°¾éƒ¨çš„å†’å·
            description = ("%11s" * 2 + "%11.3g" * 3 + "%11d" + "%11s") % (
                f"{epoch + 1}/{self.epochs}",
                mem,
                box_loss,
                cls_loss,
                dfl_loss,
                instances,
                f"{img_size}"
            )
            pbar.set_description(description)


    def preprocess_batch(self, batch):
        """é¢„å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼Œå¹¶è·Ÿè¸ªå®ä¾‹æ•°é‡"""
        # å¦‚æœæ‰¹æ¬¡ä¸ºç©ºï¼Œåˆ™åˆ›å»ºç©ºå­—å…¸
        if batch is None:
            return {'img': None}

        # åœ¨å¤„ç†å‰ç»Ÿè®¡å®ä¾‹æ•°
        instance_count = 0
        if 'bboxes' in batch:
            bboxes = batch['bboxes']
            if isinstance(bboxes, list):
                instance_count = sum(len(b) for b in bboxes if b is not None)
            elif torch.is_tensor(bboxes) and bboxes.numel() > 0:
                instance_count = bboxes.shape[0]

        # ä¿å­˜å½“å‰æ‰¹æ¬¡çš„å®ä¾‹æ•°é‡
        if not hasattr(self, '_instance_counts'):
            self._instance_counts = {}
        self._instance_counts[self.batch_i] = instance_count

        # ä¿å­˜å½“å‰æ‰¹æ¬¡å¼•ç”¨
        self.current_batch = batch

        # å°†å›¾åƒç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼Œå¹¶ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        if 'img' in batch:
            # æ£€æŸ¥å›¾åƒæ•°æ®ç±»å‹å¹¶è¿›è¡Œå¿…è¦çš„è½¬æ¢
            img = batch['img']

            # å¦‚æœå›¾åƒæ˜¯æµ®ç‚¹å‹ï¼Œç¡®ä¿å·²ç»å½’ä¸€åŒ–
            if img.dtype == torch.float32:
                # ç¡®ä¿æ•°å€¼èŒƒå›´åœ¨[0,1]
                if img.max() > 1.0:
                    img = img / 255.0
            # å¦‚æœå›¾åƒæ˜¯æ•´å‹ï¼Œè½¬æ¢ä¸ºæµ®ç‚¹å‹å¹¶å½’ä¸€åŒ–
            elif img.dtype == torch.uint8:
                img = img.float() / 255.0

            # å°†å¤„ç†åçš„å›¾åƒç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            batch['img'] = img.to(self.device, non_blocking=True)

        # ç¡®ä¿æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å…ƒç´ éƒ½åœ¨ç›¸åŒè®¾å¤‡ä¸Š
        for k in batch:
            if k != 'img' and torch.is_tensor(batch[k]):
                batch[k] = batch[k].to(self.device, non_blocking=True)

        # ç‰¹åˆ«å¤„ç†batch_idxï¼Œç¡®ä¿å®ƒå­˜åœ¨ä¸”åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
        if 'batch_idx' not in batch and 'cls' in batch and 'bboxes' in batch:
            # è®¡ç®—æ¯ä¸ªæ ‡ç­¾å¯¹åº”çš„æ‰¹æ¬¡ç´¢å¼•
            cls_tensor = batch['cls']
            if len(cls_tensor.shape) == 1:
                num_labels = cls_tensor.shape[0]
            else:
                num_labels = cls_tensor.shape[0] * cls_tensor.shape[1]

            # åˆ›å»ºæ‰¹æ¬¡ç´¢å¼•å¼ é‡
            if num_labels > 0:
                # å¦‚æœæ ‡ç­¾ä¸ä¸ºç©ºï¼Œä¸ºæ¯ä¸ªæ ‡ç­¾åˆ†é…æ‰¹æ¬¡ç´¢å¼•
                # å‡è®¾æ¯ä¸ªå›¾åƒæœ‰ç›¸åŒæ•°é‡çš„æ ‡ç­¾
                batch_size = batch['img'].shape[0]
                labels_per_image = num_labels // batch_size
                batch['batch_idx'] = torch.arange(batch_size, device=self.device).repeat_interleave(labels_per_image)
            else:
                # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œåˆ›å»ºç©ºå¼ é‡
                batch['batch_idx'] = torch.tensor([], device=self.device)

        return batch

    def save_model(self):
        """ä¿å­˜åŒ…å«åŸŸé€‚åº”ç»„ä»¶çš„æ¨¡å‹"""
        try:
            # ç¡®ä¿CSVæ–‡ä»¶å­˜åœ¨
            self.create_empty_results_csv()

            # å°è¯•æ ‡å‡†ä¿å­˜æ–¹æ³•
            super().save_model()
        except Exception as e:
            LOGGER.error(f"Error in standard save_model: {e}")
            import traceback
            LOGGER.error(traceback.format_exc())

            # å¤‡ä»½ä¿å­˜æ–¹æ³•
            try:
                # ä¿å­˜æœ€å°æ¨¡å‹æƒé‡
                ckpt = {
                    'epoch': self.epoch,
                    'model': de_parallel(self.model).state_dict(),
                    'date': datetime.now().isoformat()
                }
                save_path = str(self.save_dir / f'backup_epoch_{self.epoch}.pt')
                torch.save(ckpt, save_path)
                LOGGER.info(f"Saved backup model to {save_path}")
            except Exception as backup_e:
                LOGGER.error(f"Even backup save failed: {backup_e}")

        # åˆ¤åˆ«å™¨ä¿å­˜é€»è¾‘ - æ¯ 10 ä¸ª epoch ä¿å­˜ä¸€æ¬¡
        try:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä¿å­˜åˆ¤åˆ«å™¨
            should_save = (self.epoch % 10 == 0) and (self.epoch != 0)  # æ¯ 10 ä¸ª epoch
            is_final_epoch = (self.epoch == self.epochs - 1)  # æˆ–æœ€åä¸€ä¸ª epoch

            # åœ¨è¾¾åˆ°ä¿å­˜æ¡ä»¶æ—¶ä¿å­˜åˆ¤åˆ«å™¨
            if self.domain_adapt_enabled and self.discriminator is not None and (should_save or is_final_epoch):
                discriminator = de_parallel(self.discriminator)

                # æ ¹æ®æƒ…å†µå‘½åä¿å­˜æ–‡ä»¶
                if is_final_epoch:
                    # æœ€ç»ˆæ¨¡å‹ä½¿ç”¨ç‰¹æ®Šå‘½å
                    disc_path = str(self.save_dir / 'discriminator_final.pt')
                    LOGGER.info(f"Saved final discriminator to {disc_path}")
                else:
                    # ä¸­é—´æ£€æŸ¥ç‚¹ä½¿ç”¨ epoch ç¼–å·
                    disc_path = str(self.save_dir / f'discriminator_epoch{self.epoch}.pt')
                    LOGGER.info(f"Saved checkpoint discriminator at epoch {self.epoch}")

                # ä¿å­˜æ¨¡å‹
                torch.save(discriminator.state_dict(), disc_path)
            # else:
            #     # è®°å½•è·³è¿‡ä¿å­˜çš„æ—¥å¿—
            #     if self.domain_adapt_enabled and self.discriminator is not None:
            #         LOGGER.info(f"Skipping discriminator save for epoch {self.epoch} (not at save interval)")
        except Exception as e:
            LOGGER.error(f"Error saving discriminator: {e}")