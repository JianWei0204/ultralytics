# Ultralytics YOLO ğŸš€, AGPL-3.0 license

"""
åŒåŸŸæ•°æ®åŠ è½½å™¨ (Dual-Domain DataLoader)
ç”¨äºDayâ†’RainåŸŸé€‚åº”çš„æ•°æ®åŠ è½½å’Œé¢„å¤„ç†

ä¸»è¦åŠŸèƒ½ï¼š
1. åŒæ—¶åŠ è½½æºåŸŸ(Day)å’Œç›®æ ‡åŸŸ(Rain)æ•°æ®
2. æ•°æ®å¢å¼ºå’Œé¢„å¤„ç†
3. æ‰¹æ¬¡åŒæ­¥å’Œå¹³è¡¡
4. å¤©æ°”æ ‡ç­¾ç”Ÿæˆ
"""

import torch
import numpy as np
import random
from torch.utils.data import DataLoader, Dataset, Sampler
from typing import Dict, List, Tuple, Optional, Union
import yaml
from pathlib import Path

from ultralytics.data.dataset import YOLODataset
from ultralytics.data.build import build_dataloader
from ultralytics.utils import LOGGER


class DualDomainDataLoader:
    """
    åŒåŸŸæ•°æ®åŠ è½½å™¨
    
    åŒæ—¶å¤„ç†æºåŸŸ(Day)å’Œç›®æ ‡åŸŸ(Rain)æ•°æ®ï¼Œç¡®ä¿æ¯ä¸ªæ‰¹æ¬¡åŒ…å«ä¸¤ä¸ªåŸŸçš„æ•°æ®
    """
    
    def __init__(self,
                 source_cfg: Union[str, Dict],
                 target_cfg: Union[str, Dict],
                 batch_size: int = 16,
                 img_size: int = 640,
                 workers: int = 8,
                 shuffle: bool = True,
                 domain_balance: float = 0.5,
                 augment: bool = True):
        """
        åˆå§‹åŒ–åŒåŸŸæ•°æ®åŠ è½½å™¨
        
        Args:
            source_cfg: æºåŸŸæ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é…ç½®å­—å…¸
            target_cfg: ç›®æ ‡åŸŸæ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é…ç½®å­—å…¸  
            batch_size: æ‰¹æ¬¡å¤§å°
            img_size: å›¾åƒå°ºå¯¸
            workers: å·¥ä½œçº¿ç¨‹æ•°
            shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
            domain_balance: åŸŸå¹³è¡¡æ¯”ä¾‹ (0.5è¡¨ç¤ºæºåŸŸå’Œç›®æ ‡åŸŸå„å 50%)
            augment: æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
        """
        self.batch_size = batch_size
        self.img_size = img_size
        self.workers = workers
        self.shuffle = shuffle
        self.domain_balance = domain_balance
        self.augment = augment
        
        # åŠ è½½é…ç½®
        self.source_cfg = self._load_config(source_cfg)
        self.target_cfg = self._load_config(target_cfg)
        
        # åˆ›å»ºæ•°æ®é›†
        self.source_dataset = self._create_dataset(self.source_cfg, domain_type='source')
        self.target_dataset = self._create_dataset(self.target_cfg, domain_type='target')
        
        # è®¡ç®—æ¯ä¸ªåŸŸçš„æ‰¹æ¬¡å¤§å°
        self.source_batch_size = int(batch_size * domain_balance)
        self.target_batch_size = batch_size - self.source_batch_size
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.source_loader = self._create_dataloader(self.source_dataset, self.source_batch_size)
        self.target_loader = self._create_dataloader(self.target_dataset, self.target_batch_size)
        
        # åˆ›å»ºè¿­ä»£å™¨
        self.source_iter = iter(self.source_loader)
        self.target_iter = iter(self.target_loader)
        
        LOGGER.info(f"åŒåŸŸæ•°æ®åŠ è½½å™¨åˆå§‹åŒ–å®Œæˆ:")
        LOGGER.info(f"  æºåŸŸ(Day): {len(self.source_dataset)} æ ·æœ¬, æ‰¹æ¬¡å¤§å°: {self.source_batch_size}")
        LOGGER.info(f"  ç›®æ ‡åŸŸ(Rain): {len(self.target_dataset)} æ ·æœ¬, æ‰¹æ¬¡å¤§å°: {self.target_batch_size}")
        
    def _load_config(self, cfg: Union[str, Dict]) -> Dict:
        """
        åŠ è½½æ•°æ®é›†é…ç½®
        
        Args:
            cfg: é…ç½®æ–‡ä»¶è·¯å¾„æˆ–é…ç½®å­—å…¸
            
        Returns:
            Dict: é…ç½®å­—å…¸
        """
        if isinstance(cfg, str):
            with open(cfg, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return cfg
        
    def _create_dataset(self, cfg: Dict, domain_type: str) -> YOLODataset:
        """
        åˆ›å»ºYOLOæ•°æ®é›†
        
        Args:
            cfg: æ•°æ®é›†é…ç½®
            domain_type: åŸŸç±»å‹ ('source' æˆ– 'target')
            
        Returns:
            YOLODataset: YOLOæ•°æ®é›†å®ä¾‹
        """
        # æ„å»ºæ•°æ®é›†å‚æ•°
        dataset_args = {
            'img_path': cfg['train'],
            'imgsz': self.img_size,
            'augment': self.augment,
            'cache': False,  # ä¸ä½¿ç”¨ç¼“å­˜ä»¥èŠ‚çœå†…å­˜
            'prefix': f'{domain_type}: '
        }
        
        # åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†ï¼Œæ·»åŠ åŸŸæ ‡ç­¾
        dataset = DomainYOLODataset(**dataset_args, domain_type=domain_type)
        
        return dataset
        
    def _create_dataloader(self, dataset: Dataset, batch_size: int) -> DataLoader:
        """
        åˆ›å»ºæ•°æ®åŠ è½½å™¨
        
        Args:
            dataset: æ•°æ®é›†
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            DataLoader: æ•°æ®åŠ è½½å™¨
        """
        return DataLoader(
            dataset,
            batch_size=batch_size,
            shuffle=self.shuffle,
            num_workers=self.workers,
            pin_memory=True,
            collate_fn=dataset.collate_fn,
            drop_last=True  # ç¡®ä¿æ‰¹æ¬¡å¤§å°ä¸€è‡´
        )
        
    def __iter__(self):
        """åˆ›å»ºè¿­ä»£å™¨"""
        return self
        
    def __next__(self) -> Dict[str, torch.Tensor]:
        """
        è·å–ä¸‹ä¸€ä¸ªæ‰¹æ¬¡
        
        Returns:
            Dict: åŒ…å«æºåŸŸå’Œç›®æ ‡åŸŸæ•°æ®çš„å­—å…¸
        """
        try:
            # è·å–æºåŸŸæ•°æ®
            try:
                source_batch = next(self.source_iter)
            except StopIteration:
                self.source_iter = iter(self.source_loader)
                source_batch = next(self.source_iter)
                
            # è·å–ç›®æ ‡åŸŸæ•°æ®
            try:
                target_batch = next(self.target_iter)
            except StopIteration:
                self.target_iter = iter(self.target_loader)
                target_batch = next(self.target_iter)
                
            # åˆå¹¶æ‰¹æ¬¡æ•°æ®
            combined_batch = self._combine_batches(source_batch, target_batch)
            
            return combined_batch
            
        except Exception as e:
            LOGGER.error(f"æ•°æ®åŠ è½½é”™è¯¯: {e}")
            raise StopIteration
            
    def _combine_batches(self, source_batch: Dict, target_batch: Dict) -> Dict[str, torch.Tensor]:
        """
        åˆå¹¶æºåŸŸå’Œç›®æ ‡åŸŸæ‰¹æ¬¡
        
        Args:
            source_batch: æºåŸŸæ‰¹æ¬¡æ•°æ®
            target_batch: ç›®æ ‡åŸŸæ‰¹æ¬¡æ•°æ®
            
        Returns:
            Dict: åˆå¹¶åçš„æ‰¹æ¬¡æ•°æ®
        """
        # åˆå¹¶å›¾åƒ
        source_imgs = source_batch['img']  # [B1, C, H, W]
        target_imgs = target_batch['img']  # [B2, C, H, W]
        combined_imgs = torch.cat([source_imgs, target_imgs], dim=0)
        
        # åˆ›å»ºåŸŸæ ‡ç­¾ (0: æºåŸŸ, 1: ç›®æ ‡åŸŸ)
        source_domain_labels = torch.zeros(source_imgs.size(0), dtype=torch.long)
        target_domain_labels = torch.ones(target_imgs.size(0), dtype=torch.long)
        domain_labels = torch.cat([source_domain_labels, target_domain_labels], dim=0)
        
        # åˆ›å»ºå¤©æ°”æ ‡ç­¾ (0: Day, 1: Rain)
        weather_labels = domain_labels.clone()  # ç®€åŒ–ç‰ˆæœ¬ï¼ŒåŸŸæ ‡ç­¾å³å¤©æ°”æ ‡ç­¾
        
        # åˆå¹¶æ ‡ç­¾æ•°æ® (å¦‚æœå­˜åœ¨)
        combined_batch = {
            'img': combined_imgs,
            'domain_labels': domain_labels,
            'weather_labels': weather_labels,
            'batch_idx': torch.arange(combined_imgs.size(0)),
        }
        
        # å¤„ç†ç›®æ ‡æ£€æµ‹æ ‡ç­¾
        if 'bboxes' in source_batch and 'bboxes' in target_batch:
            # åˆå¹¶è¾¹ç•Œæ¡†
            source_bboxes = source_batch['bboxes']
            target_bboxes = target_batch['bboxes']
            
            # è°ƒæ•´æ‰¹æ¬¡ç´¢å¼•
            if hasattr(target_bboxes, 'shape') and len(target_bboxes.shape) > 1:
                if target_bboxes.size(1) > 0:  # å¦‚æœæœ‰è¾¹ç•Œæ¡†
                    target_bboxes[:, 0] += source_imgs.size(0)  # è°ƒæ•´æ‰¹æ¬¡ç´¢å¼•
                    
            combined_bboxes = torch.cat([source_bboxes, target_bboxes], dim=0)
            combined_batch['bboxes'] = combined_bboxes
            
        # å¤„ç†ç±»åˆ«æ ‡ç­¾
        if 'cls' in source_batch and 'cls' in target_batch:
            combined_cls = torch.cat([source_batch['cls'], target_batch['cls']], dim=0)
            combined_batch['cls'] = combined_cls
            
        return combined_batch
        
    def __len__(self) -> int:
        """è¿”å›æ•°æ®é›†é•¿åº¦"""
        return min(len(self.source_loader), len(self.target_loader))
        
    def reset(self):
        """é‡ç½®è¿­ä»£å™¨"""
        self.source_iter = iter(self.source_loader)
        self.target_iter = iter(self.target_loader)


class DomainYOLODataset(YOLODataset):
    """
    å¸¦åŸŸæ ‡ç­¾çš„YOLOæ•°æ®é›†
    
    æ‰©å±•æ ‡å‡†YOLOæ•°æ®é›†ï¼Œæ·»åŠ åŸŸä¿¡æ¯
    """
    
    def __init__(self, domain_type: str = 'source', **kwargs):
        """
        åˆå§‹åŒ–åŸŸYOLOæ•°æ®é›†
        
        Args:
            domain_type: åŸŸç±»å‹ ('source' æˆ– 'target')
            **kwargs: å…¶ä»–YOLOæ•°æ®é›†å‚æ•°
        """
        super().__init__(**kwargs)
        self.domain_type = domain_type
        self.domain_label = 0 if domain_type == 'source' else 1
        
    def __getitem__(self, index):
        """
        è·å–æ•°æ®é¡¹
        
        Args:
            index: æ•°æ®ç´¢å¼•
            
        Returns:
            Dict: åŒ…å«åŸŸä¿¡æ¯çš„æ•°æ®é¡¹
        """
        # è·å–åŸå§‹æ•°æ®
        data = super().__getitem__(index)
        
        # æ·»åŠ åŸŸä¿¡æ¯
        if isinstance(data, dict):
            data['domain_label'] = self.domain_label
            data['domain_type'] = self.domain_type
        
        return data


class WeatherAugmentation:
    """
    å¤©æ°”å¢å¼ºç±»
    
    ä¸“é—¨ç”¨äºæ¨¡æ‹Ÿä¸åŒå¤©æ°”æ¡ä»¶çš„æ•°æ®å¢å¼º
    """
    
    def __init__(self, rain_intensity: float = 0.3, fog_density: float = 0.2):
        """
        åˆå§‹åŒ–å¤©æ°”å¢å¼º
        
        Args:
            rain_intensity: é›¨å¼ºåº¦
            fog_density: é›¾å¯†åº¦
        """
        self.rain_intensity = rain_intensity
        self.fog_density = fog_density
        
    def add_rain(self, image: torch.Tensor) -> torch.Tensor:
        """
        æ·»åŠ é›¨æ•ˆæœ
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W]
            
        Returns:
            torch.Tensor: å¸¦é›¨æ•ˆæœçš„å›¾åƒ
        """
        if random.random() > 0.5:  # 50%æ¦‚ç‡æ·»åŠ é›¨æ•ˆæœ
            return image
            
        # ç®€å•çš„é›¨æ•ˆæœï¼šæ·»åŠ å‚ç›´çº¿æ¡
        _, h, w = image.shape
        rain_mask = torch.zeros_like(image)
        
        # éšæœºç”Ÿæˆé›¨æ»´ä½ç½®
        num_drops = int(h * w * self.rain_intensity * 0.001)
        for _ in range(num_drops):
            x = random.randint(0, w - 1)
            y_start = random.randint(0, h // 2)
            y_end = min(y_start + random.randint(10, 30), h - 1)
            
            # ç»˜åˆ¶é›¨æ»´
            for y in range(y_start, y_end):
                if y < h and x < w:
                    rain_mask[:, y, x] = 0.3
                    
        # åº”ç”¨é›¨æ•ˆæœ
        rainy_image = image * (1 - rain_mask) + rain_mask
        return torch.clamp(rainy_image, 0, 1)
        
    def add_fog(self, image: torch.Tensor) -> torch.Tensor:
        """
        æ·»åŠ é›¾æ•ˆæœ
        
        Args:
            image: è¾“å…¥å›¾åƒ [C, H, W]
            
        Returns:
            torch.Tensor: å¸¦é›¾æ•ˆæœçš„å›¾åƒ
        """
        if random.random() > 0.3:  # 30%æ¦‚ç‡æ·»åŠ é›¾æ•ˆæœ
            return image
            
        # ç®€å•çš„é›¾æ•ˆæœï¼šæ·»åŠ ç™½è‰²é®ç½©
        fog_mask = torch.ones_like(image) * self.fog_density
        foggy_image = image * (1 - self.fog_density) + fog_mask
        return torch.clamp(foggy_image, 0, 1)
        
    def __call__(self, image: torch.Tensor, weather_type: str = 'rain') -> torch.Tensor:
        """
        åº”ç”¨å¤©æ°”å¢å¼º
        
        Args:
            image: è¾“å…¥å›¾åƒ
            weather_type: å¤©æ°”ç±»å‹ ('rain' æˆ– 'fog')
            
        Returns:
            torch.Tensor: å¢å¼ºåçš„å›¾åƒ
        """
        if weather_type == 'rain':
            return self.add_rain(image)
        elif weather_type == 'fog':
            return self.add_fog(image)
        else:
            return image


def create_dual_domain_dataloader(source_data: str,
                                  target_data: str,
                                  batch_size: int = 16,
                                  img_size: int = 640,
                                  workers: int = 8,
                                  **kwargs) -> DualDomainDataLoader:
    """
    åˆ›å»ºåŒåŸŸæ•°æ®åŠ è½½å™¨çš„ä¾¿æ·å‡½æ•°
    
    Args:
        source_data: æºåŸŸæ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        target_data: ç›®æ ‡åŸŸæ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
        batch_size: æ‰¹æ¬¡å¤§å°
        img_size: å›¾åƒå°ºå¯¸
        workers: å·¥ä½œçº¿ç¨‹æ•°
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        DualDomainDataLoader: åŒåŸŸæ•°æ®åŠ è½½å™¨
    """
    return DualDomainDataLoader(
        source_cfg=source_data,
        target_cfg=target_data,
        batch_size=batch_size,
        img_size=img_size,
        workers=workers,
        **kwargs
    )