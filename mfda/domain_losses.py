# Ultralytics YOLO ğŸš€, AGPL-3.0 license

"""
åŸŸå¯¹æŠ—æŸå¤±å‡½æ•° (Domain Adversarial Loss Functions)
ç”¨äºDayâ†’RainåŸŸé€‚åº”çš„æŸå¤±å‡½æ•°é›†åˆ

ä¸»è¦åŠŸèƒ½ï¼š
1. åŸŸåˆ†ç±»æŸå¤±
2. ä¸€è‡´æ€§æŸå¤±
3. å¯¹æŠ—æŸå¤±
4. ç‰¹å¾å¯¹é½æŸå¤±
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Optional, Tuple
import math


class DomainAdversarialLoss(nn.Module):
    """
    åŸŸå¯¹æŠ—æŸå¤±
    
    é€šè¿‡æ¢¯åº¦åè½¬å±‚å®ç°åŸŸå¯¹æŠ—è®­ç»ƒï¼Œä½¿ç‰¹å¾æå–å™¨å­¦ä¹ åŸŸä¸å˜ç‰¹å¾
    """
    
    def __init__(self, 
                 input_dim: int = 256,
                 hidden_dim: int = 128,
                 grl_weight: float = 1.0):
        """
        åˆå§‹åŒ–åŸŸå¯¹æŠ—æŸå¤±
        
        Args:
            input_dim: è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_dim: éšè—å±‚ç»´åº¦  
            grl_weight: æ¢¯åº¦åè½¬å±‚æƒé‡
        """
        super(DomainAdversarialLoss, self).__init__()
        
        self.grl_weight = grl_weight
        
        # åŸŸåˆ†ç±»å™¨
        self.domain_classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim // 2, 1)  # äºŒåˆ†ç±»ï¼šæºåŸŸ(0) vs ç›®æ ‡åŸŸ(1)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
    def _init_weights(self):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
                    
    def gradient_reverse_layer(self, x: torch.Tensor) -> torch.Tensor:
        """
        æ¢¯åº¦åè½¬å±‚
        
        Args:
            x: è¾“å…¥ç‰¹å¾
            
        Returns:
            torch.Tensor: ç»è¿‡æ¢¯åº¦åè½¬çš„ç‰¹å¾
        """
        return GradientReverseFunction.apply(x, self.grl_weight)
        
    def forward(self, 
                source_features: torch.Tensor,
                target_features: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            source_features: æºåŸŸç‰¹å¾ [B, C, H, W]
            target_features: ç›®æ ‡åŸŸç‰¹å¾ [B, C, H, W]
            
        Returns:
            Dict: åŒ…å«å„ç§æŸå¤±çš„å­—å…¸
        """
        # åˆå¹¶æºåŸŸå’Œç›®æ ‡åŸŸç‰¹å¾
        all_features = torch.cat([source_features, target_features], dim=0)
        
        # é€šè¿‡æ¢¯åº¦åè½¬å±‚
        reversed_features = self.gradient_reverse_layer(all_features)
        
        # åŸŸåˆ†ç±»
        domain_predictions = self.domain_classifier(reversed_features)
        
        # åˆ›å»ºåŸŸæ ‡ç­¾
        batch_size = source_features.size(0)
        source_labels = torch.zeros(batch_size, 1, device=source_features.device)
        target_labels = torch.ones(batch_size, 1, device=target_features.device)
        domain_labels = torch.cat([source_labels, target_labels], dim=0)
        
        # è®¡ç®—åŸŸåˆ†ç±»æŸå¤±
        domain_loss = F.binary_cross_entropy_with_logits(domain_predictions, domain_labels)
        
        # è®¡ç®—åŸŸåˆ†ç±»å‡†ç¡®ç‡
        with torch.no_grad():
            predictions = torch.sigmoid(domain_predictions) > 0.5
            accuracy = (predictions.float() == domain_labels).float().mean()
            
        return {
            'domain_loss': domain_loss,
            'domain_accuracy': accuracy,
            'domain_predictions': torch.sigmoid(domain_predictions)
        }


class ConsistencyLoss(nn.Module):
    """
    ä¸€è‡´æ€§æŸå¤±
    
    ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒåŸŸä¸Šçš„é¢„æµ‹ä¿æŒä¸€è‡´æ€§
    """
    
    def __init__(self, 
                 temperature: float = 0.5,
                 consistency_weight: float = 1.0):
        """
        åˆå§‹åŒ–ä¸€è‡´æ€§æŸå¤±
        
        Args:
            temperature: è½¯æ ‡ç­¾æ¸©åº¦å‚æ•°
            consistency_weight: ä¸€è‡´æ€§æŸå¤±æƒé‡
        """
        super(ConsistencyLoss, self).__init__()
        
        self.temperature = temperature
        self.consistency_weight = consistency_weight
        
    def forward(self, 
                source_predictions: torch.Tensor,
                target_predictions: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—ä¸€è‡´æ€§æŸå¤±
        
        Args:
            source_predictions: æºåŸŸé¢„æµ‹ [B, num_classes, ...]
            target_predictions: ç›®æ ‡åŸŸé¢„æµ‹ [B, num_classes, ...]
            
        Returns:
            torch.Tensor: ä¸€è‡´æ€§æŸå¤±
        """
        # å°†é¢„æµ‹è½¬æ¢ä¸ºæ¦‚ç‡åˆ†å¸ƒ
        source_probs = F.softmax(source_predictions / self.temperature, dim=1)
        target_probs = F.softmax(target_predictions / self.temperature, dim=1)
        
        # è®¡ç®—KLæ•£åº¦
        kl_loss = F.kl_div(
            F.log_softmax(target_predictions / self.temperature, dim=1),
            source_probs,
            reduction='batchmean'
        )
        
        return self.consistency_weight * kl_loss


class FeatureAlignmentLoss(nn.Module):
    """
    ç‰¹å¾å¯¹é½æŸå¤±
    
    ä½¿æºåŸŸå’Œç›®æ ‡åŸŸçš„ç‰¹å¾åˆ†å¸ƒå¯¹é½
    """
    
    def __init__(self, alignment_weight: float = 1.0):
        """
        åˆå§‹åŒ–ç‰¹å¾å¯¹é½æŸå¤±
        
        Args:
            alignment_weight: å¯¹é½æŸå¤±æƒé‡
        """
        super(FeatureAlignmentLoss, self).__init__()
        
        self.alignment_weight = alignment_weight
        
    def mmd_loss(self, 
                 source_features: torch.Tensor,
                 target_features: torch.Tensor,
                 kernel_type: str = 'gaussian') -> torch.Tensor:
        """
        æœ€å¤§å‡å€¼å·®å¼‚(MMD)æŸå¤±
        
        Args:
            source_features: æºåŸŸç‰¹å¾
            target_features: ç›®æ ‡åŸŸç‰¹å¾
            kernel_type: æ ¸å‡½æ•°ç±»å‹
            
        Returns:
            torch.Tensor: MMDæŸå¤±
        """
        def gaussian_kernel(x, y, sigma=1.0):
            """é«˜æ–¯æ ¸å‡½æ•°"""
            dist = torch.cdist(x, y, p=2)
            return torch.exp(-dist ** 2 / (2 * sigma ** 2))
        
        # å±•å¹³ç‰¹å¾
        source_flat = source_features.view(source_features.size(0), -1)
        target_flat = target_features.view(target_features.size(0), -1)
        
        # è®¡ç®—æ ¸çŸ©é˜µ
        if kernel_type == 'gaussian':
            k_ss = gaussian_kernel(source_flat, source_flat).mean()
            k_tt = gaussian_kernel(target_flat, target_flat).mean()
            k_st = gaussian_kernel(source_flat, target_flat).mean()
        else:
            # çº¿æ€§æ ¸
            k_ss = torch.mm(source_flat, source_flat.t()).mean()
            k_tt = torch.mm(target_flat, target_flat.t()).mean()
            k_st = torch.mm(source_flat, target_flat.t()).mean()
            
        # MMDæŸå¤±
        mmd = k_ss + k_tt - 2 * k_st
        return mmd
        
    def forward(self, 
                source_features: torch.Tensor,
                target_features: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—ç‰¹å¾å¯¹é½æŸå¤±
        
        Args:
            source_features: æºåŸŸç‰¹å¾
            target_features: ç›®æ ‡åŸŸç‰¹å¾
            
        Returns:
            torch.Tensor: ç‰¹å¾å¯¹é½æŸå¤±
        """
        mmd = self.mmd_loss(source_features, target_features)
        return self.alignment_weight * mmd


class AdversarialWeatherLoss(nn.Module):
    """
    å¯¹æŠ—å¤©æ°”æŸå¤±
    
    ä¸“é—¨ç”¨äºDayâ†’RainåŸŸé€‚åº”çš„æŸå¤±å‡½æ•°
    """
    
    def __init__(self, 
                 weather_weight: float = 1.0,
                 num_weather_classes: int = 2):  # Day, Rain
        """
        åˆå§‹åŒ–å¯¹æŠ—å¤©æ°”æŸå¤±
        
        Args:
            weather_weight: å¤©æ°”æŸå¤±æƒé‡
            num_weather_classes: å¤©æ°”ç±»åˆ«æ•°é‡
        """
        super(AdversarialWeatherLoss, self).__init__()
        
        self.weather_weight = weather_weight
        self.num_weather_classes = num_weather_classes
        
        # å¤©æ°”åˆ†ç±»å™¨
        self.weather_classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(128, num_weather_classes)
        )
        
    def forward(self, 
                features: torch.Tensor,
                weather_labels: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—å¯¹æŠ—å¤©æ°”æŸå¤±
        
        Args:
            features: è¾“å…¥ç‰¹å¾ [B, C, H, W]
            weather_labels: å¤©æ°”æ ‡ç­¾ [B] (0: Day, 1: Rain)
            
        Returns:
            Dict: åŒ…å«å¤©æ°”æŸå¤±å’Œå‡†ç¡®ç‡çš„å­—å…¸
        """
        # å¤©æ°”åˆ†ç±»é¢„æµ‹
        weather_predictions = self.weather_classifier(features)
        
        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        weather_loss = F.cross_entropy(weather_predictions, weather_labels.long())
        
        # è®¡ç®—å‡†ç¡®ç‡
        with torch.no_grad():
            predictions = torch.argmax(weather_predictions, dim=1)
            accuracy = (predictions == weather_labels).float().mean()
            
        return {
            'weather_loss': self.weather_weight * weather_loss,
            'weather_accuracy': accuracy,
            'weather_predictions': F.softmax(weather_predictions, dim=1)
        }


class GradientReverseFunction(torch.autograd.Function):
    """
    æ¢¯åº¦åè½¬å‡½æ•°
    
    å‰å‘ä¼ æ’­æ—¶ä¿æŒè¾“å…¥ä¸å˜ï¼Œåå‘ä¼ æ’­æ—¶å°†æ¢¯åº¦ä¹˜ä»¥è´Ÿæƒé‡
    """
    
    @staticmethod
    def forward(ctx, x, weight):
        ctx.weight = weight
        return x.view_as(x)
        
    @staticmethod
    def backward(ctx, grad_output):
        return -ctx.weight * grad_output, None


class MFDAMLoss(nn.Module):
    """
    MFDAMç»¼åˆæŸå¤±å‡½æ•°
    
    æ•´åˆæ‰€æœ‰åŸŸé€‚åº”ç›¸å…³çš„æŸå¤±å‡½æ•°
    """
    
    def __init__(self, 
                 domain_weight: float = 1.0,
                 consistency_weight: float = 0.5,
                 alignment_weight: float = 0.3,
                 weather_weight: float = 0.7):
        """
        åˆå§‹åŒ–MFDAMæŸå¤±
        
        Args:
            domain_weight: åŸŸå¯¹æŠ—æŸå¤±æƒé‡
            consistency_weight: ä¸€è‡´æ€§æŸå¤±æƒé‡
            alignment_weight: ç‰¹å¾å¯¹é½æŸå¤±æƒé‡
            weather_weight: å¤©æ°”å¯¹æŠ—æŸå¤±æƒé‡
        """
        super(MFDAMLoss, self).__init__()
        
        self.domain_adversarial = DomainAdversarialLoss()
        self.consistency = ConsistencyLoss(consistency_weight=consistency_weight)
        self.alignment = FeatureAlignmentLoss(alignment_weight=alignment_weight)
        self.weather = AdversarialWeatherLoss(weather_weight=weather_weight)
        
        self.domain_weight = domain_weight
        
    def forward(self, 
                source_features: torch.Tensor,
                target_features: torch.Tensor,
                source_predictions: Optional[torch.Tensor] = None,
                target_predictions: Optional[torch.Tensor] = None,
                weather_labels: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—æ€»æŸå¤±
        
        Args:
            source_features: æºåŸŸç‰¹å¾
            target_features: ç›®æ ‡åŸŸç‰¹å¾
            source_predictions: æºåŸŸé¢„æµ‹ (å¯é€‰)
            target_predictions: ç›®æ ‡åŸŸé¢„æµ‹ (å¯é€‰)
            weather_labels: å¤©æ°”æ ‡ç­¾ (å¯é€‰)
            
        Returns:
            Dict: åŒ…å«å„ç§æŸå¤±çš„å­—å…¸
        """
        losses = {}
        total_loss = 0
        
        # åŸŸå¯¹æŠ—æŸå¤±
        domain_results = self.domain_adversarial(source_features, target_features)
        losses.update(domain_results)
        total_loss += self.domain_weight * domain_results['domain_loss']
        
        # ä¸€è‡´æ€§æŸå¤±
        if source_predictions is not None and target_predictions is not None:
            consistency_loss = self.consistency(source_predictions, target_predictions)
            losses['consistency_loss'] = consistency_loss
            total_loss += consistency_loss
            
        # ç‰¹å¾å¯¹é½æŸå¤±
        alignment_loss = self.alignment(source_features, target_features)
        losses['alignment_loss'] = alignment_loss
        total_loss += alignment_loss
        
        # å¤©æ°”å¯¹æŠ—æŸå¤±
        if weather_labels is not None:
            all_features = torch.cat([source_features, target_features], dim=0)
            weather_results = self.weather(all_features, weather_labels)
            losses.update(weather_results)
            total_loss += weather_results['weather_loss']
            
        losses['total_da_loss'] = total_loss
        return losses