#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
MFDAMå¿«é€Ÿå…¥é—¨æ•™ç¨‹ (MFDAM Quick Start Tutorial)
å¸®åŠ©ç”¨æˆ·å¿«é€Ÿä¸Šæ‰‹Dayâ†’RainåŸŸé€‚åº”è®­ç»ƒ

ä½¿ç”¨æ–¹æ³•:
python mfda_quick_start.py
"""

import torch
import sys
import os
from pathlib import Path

# æ·»åŠ ultralyticsåˆ°è·¯å¾„
sys.path.append('.')
sys.path.append('ultralytics')

def print_header(title):
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"ğŸ“‹ {title}")
    print("=" * 60)

def print_step(step_num, title):
    """æ‰“å°æ­¥éª¤"""
    print(f"\nğŸ”¹ æ­¥éª¤ {step_num}: {title}")
    print("-" * 40)

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒä¾èµ–"""
    print_header("ç¯å¢ƒæ£€æŸ¥")
    
    requirements = {
        'torch': 'PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶',
        'yaml': 'YAMLé…ç½®æ–‡ä»¶æ”¯æŒ',
        'pathlib': 'Pythonè·¯å¾„æ“ä½œ'
    }
    
    missing = []
    for pkg, desc in requirements.items():
        try:
            __import__(pkg)
            print(f"âœ… {pkg}: {desc}")
        except ImportError:
            print(f"âŒ {pkg}: {desc} - æœªå®‰è£…")
            missing.append(pkg)
    
    if missing:
        print(f"\nâš ï¸ ç¼ºå°‘ä¾èµ–: {', '.join(missing)}")
        print("è¯·å…ˆå®‰è£…: pip install torch pyyaml")
        return False
    
    print("\nâœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡!")
    return True

def demonstrate_core_features():
    """æ¼”ç¤ºæ ¸å¿ƒåŠŸèƒ½"""
    print_header("MFDAMæ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º")
    
    try:
        from mfda.config import MFDAMConfig, DAY_RAIN_CONFIG
        from mfda.multi_scale_extractor import MultiScaleFeatureExtractor
        from mfda.domain_losses import MFDAMLoss
        
        print_step(1, "é…ç½®ç®¡ç†")
        config = DAY_RAIN_CONFIG
        print(f"  Dayâ†’Rainä¼˜åŒ–é…ç½®å·²åŠ è½½")
        print(f"  åŸŸå¹³è¡¡æ¯”ä¾‹: {config.domain_balance}")
        print(f"  åŸŸæŸå¤±æƒé‡: {config.domain_weight}")
        
        print_step(2, "å¤šå°ºåº¦ç‰¹å¾æå–")
        extractor = MultiScaleFeatureExtractor()
        print(f"  ç‰¹å¾æå–å™¨å·²åˆ›å»º")
        print(f"  æ”¯æŒ {len(extractor.feature_dims)} ä¸ªå°ºåº¦")
        print(f"  ç‰¹å¾ç»´åº¦: {extractor.feature_dims}")
        
        print_step(3, "åŸŸé€‚åº”æŸå¤±")
        loss_fn = MFDAMLoss()
        print(f"  MFDAMç»¼åˆæŸå¤±å‡½æ•°å·²åˆ›å»º")
        print(f"  åŒ…å«åŸŸå¯¹æŠ—ã€ä¸€è‡´æ€§ã€å¯¹é½ç­‰æŸå¤±")
        
        # ç®€å•æµ‹è¯•
        print_step(4, "åŠŸèƒ½æµ‹è¯•")
        source_feat = torch.randn(2, 256, 32, 32)
        target_feat = torch.randn(2, 256, 32, 32)
        weather_labels = torch.cat([torch.zeros(2), torch.ones(2)]).long()
        
        with torch.no_grad():
            results = loss_fn(source_feat, target_feat, weather_labels=weather_labels)
        
        print(f"  æµ‹è¯•æˆåŠŸ! æ€»æŸå¤±: {results['total_da_loss'].item():.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŠŸèƒ½æ¼”ç¤ºå¤±è´¥: {e}")
        return False

def create_sample_configs():
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    print_header("åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶")
    
    try:
        from mfda.config import create_day_rain_dataset_configs, save_dataset_configs
        
        print_step(1, "ç”Ÿæˆæ•°æ®é›†é…ç½®")
        
        # åˆ›å»ºç¤ºä¾‹é…ç½®
        source_config, target_config = create_day_rain_dataset_configs(
            source_train_path='datasets/day_dataset/images/train',
            source_val_path='datasets/day_dataset/images/val',
            target_train_path='datasets/rain_dataset/images/train', 
            target_val_path='datasets/rain_dataset/images/val',
            num_classes=80
        )
        
        # ä¿å­˜é…ç½®
        config_dir = Path('tutorial_configs')
        source_path, target_path = save_dataset_configs(
            source_config, target_config, config_dir
        )
        
        print(f"âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º:")
        print(f"  æºåŸŸ(Day): {source_path}")
        print(f"  ç›®æ ‡åŸŸ(Rain): {target_path}")
        
        print_step(2, "é…ç½®æ–‡ä»¶è¯´æ˜")
        print(f"  - source_day.yaml: ç™½å¤©æ™´æœ—å¤©æ°”æ•°æ®é…ç½®")
        print(f"  - target_rain.yaml: é›¨å¤©å¤©æ°”æ•°æ®é…ç½®")
        print(f"  - ä¸¤ä¸ªé…ç½®åŒ…å«ç›¸åŒçš„80ä¸ªCOCOç±»åˆ«")
        print(f"  - æ”¯æŒä¸åŒçš„æ•°æ®å¢å¼ºç­–ç•¥")
        
        return config_dir
        
    except Exception as e:
        print(f"âŒ é…ç½®åˆ›å»ºå¤±è´¥: {e}")
        return None

def show_training_commands(config_dir):
    """æ˜¾ç¤ºè®­ç»ƒå‘½ä»¤"""
    print_header("è®­ç»ƒå‘½ä»¤ç¤ºä¾‹")
    
    if config_dir is None:
        print("âš ï¸ é…ç½®æ–‡ä»¶æœªåˆ›å»ºï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„")
        source_config = "cfg/datasets/mfda/source_day.yaml"
        target_config = "cfg/datasets/mfda/target_rain.yaml"
    else:
        source_config = f"{config_dir}/source_day.yaml"
        target_config = f"{config_dir}/target_rain.yaml"
    
    print_step(1, "åŸºç¡€è®­ç»ƒå‘½ä»¤")
    basic_cmd = f"""python train_mfdam.py \\
    --source-data {source_config} \\
    --target-data {target_config} \\
    --epochs 100 \\
    --batch-size 16 \\
    --project runs/mfdam \\
    --name day2rain_experiment"""
    
    print(basic_cmd)
    
    print_step(2, "é«˜çº§é…ç½®è®­ç»ƒ")
    advanced_cmd = f"""python train_mfdam.py \\
    --source-data {source_config} \\
    --target-data {target_config} \\
    --model cfg/models/mfda/yolov8n-mfdam.yaml \\
    --epochs 200 \\
    --batch-size 32 \\
    --lr0 0.01 \\
    --da-lr 0.0005 \\
    --domain-weight 1.2 \\
    --domain-balance 0.6 \\
    --config-preset day_rain \\
    --device 0"""
    
    print(advanced_cmd)
    
    print_step(3, "å‚æ•°è¯´æ˜")
    params = {
        '--source-data': 'æºåŸŸ(Day)æ•°æ®é…ç½®æ–‡ä»¶',
        '--target-data': 'ç›®æ ‡åŸŸ(Rain)æ•°æ®é…ç½®æ–‡ä»¶', 
        '--epochs': 'è®­ç»ƒè½®æ•°',
        '--batch-size': 'æ‰¹æ¬¡å¤§å°',
        '--da-lr': 'åŸŸé€‚åº”å­¦ä¹ ç‡',
        '--domain-weight': 'åŸŸå¯¹æŠ—æŸå¤±æƒé‡',
        '--domain-balance': 'åŸŸå¹³è¡¡æ¯”ä¾‹ (>0.5åå‘ç›®æ ‡åŸŸ)',
        '--config-preset': 'MFDAMé…ç½®é¢„è®¾ (day_rainæ¨è)'
    }
    
    for param, desc in params.items():
        print(f"  {param}: {desc}")

def show_dataset_preparation():
    """æ˜¾ç¤ºæ•°æ®é›†å‡†å¤‡æŒ‡å—"""
    print_header("æ•°æ®é›†å‡†å¤‡æŒ‡å—")
    
    print_step(1, "ç›®å½•ç»“æ„")
    directory_structure = """
datasets/
â”œâ”€â”€ day_dataset/              # æºåŸŸ(ç™½å¤©æ•°æ®)
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/           # è®­ç»ƒå›¾åƒ
â”‚   â”‚   â””â”€â”€ val/             # éªŒè¯å›¾åƒ
â”‚   â””â”€â”€ labels/
â”‚       â”œâ”€â”€ train/           # è®­ç»ƒæ ‡ç­¾(YOLOæ ¼å¼)
â”‚       â””â”€â”€ val/             # éªŒè¯æ ‡ç­¾
â””â”€â”€ rain_dataset/            # ç›®æ ‡åŸŸ(é›¨å¤©æ•°æ®)
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/           # è®­ç»ƒå›¾åƒ
    â”‚   â””â”€â”€ val/             # éªŒè¯å›¾åƒ
    â””â”€â”€ labels/              # æ ‡ç­¾(å¯é€‰ï¼Œå¯æ— ç›‘ç£)
        â”œâ”€â”€ train/
        â””â”€â”€ val/
"""
    print(directory_structure)
    
    print_step(2, "æ•°æ®è¦æ±‚")
    requirements = [
        "æºåŸŸ: ç™½å¤©æ™´æœ—å¤©æ°”æ¡ä»¶ä¸‹çš„ç›®æ ‡æ£€æµ‹æ•°æ®",
        "ç›®æ ‡åŸŸ: é›¨å¤©å¤©æ°”æ¡ä»¶ä¸‹çš„æ•°æ®",
        "å›¾åƒæ ¼å¼: JPG, PNGç­‰å¸¸è§æ ¼å¼",
        "æ ‡ç­¾æ ¼å¼: YOLOæ ¼å¼ (.txtæ–‡ä»¶)",
        "å»ºè®®æºåŸŸæ•°æ®é‡: 5000+ å¼ ", 
        "å»ºè®®ç›®æ ‡åŸŸæ•°æ®é‡: 3000+ å¼ ",
        "ç›®æ ‡åŸŸå¯ä½¿ç”¨70%æ— æ ‡ç­¾æ•°æ®"
    ]
    
    for req in requirements:
        print(f"  â€¢ {req}")
    
    print_step(3, "æ•°æ®è´¨é‡å»ºè®®")
    quality_tips = [
        "ç¡®ä¿å›¾åƒè´¨é‡è‰¯å¥½ï¼Œæ ‡æ³¨å‡†ç¡®",
        "é›¨å¤©æ•°æ®åº”åŒ…å«ä¸åŒé›¨å¼º(å°é›¨ã€ä¸­é›¨ã€å¤§é›¨)",
        "ä¿æŒç±»åˆ«åˆ†å¸ƒç›¸å¯¹å¹³è¡¡",
        "å›¾åƒåˆ†è¾¨ç‡å»ºè®®ä¸ä½äº640x640",
        "é¿å…è¿‡åº¦æ›å…‰æˆ–è¿‡æš—çš„å›¾åƒ"
    ]
    
    for tip in quality_tips:
        print(f"  ğŸ’¡ {tip}")

def show_next_steps():
    """æ˜¾ç¤ºåç»­æ­¥éª¤"""
    print_header("åç»­æ­¥éª¤")
    
    steps = [
        ("å‡†å¤‡æ•°æ®é›†", "æŒ‰ç…§æŒ‡å—å‡†å¤‡Dayå’ŒRainæ•°æ®é›†"),
        ("ä¿®æ”¹é…ç½®", "ç¼–è¾‘ç”Ÿæˆçš„é…ç½®æ–‡ä»¶ï¼Œè®¾ç½®æ­£ç¡®çš„æ•°æ®è·¯å¾„"),
        ("å¼€å§‹è®­ç»ƒ", "è¿è¡Œè®­ç»ƒå‘½ä»¤å¼€å§‹Dayâ†’RainåŸŸé€‚åº”"),
        ("ç›‘æ§è®­ç»ƒ", "è§‚å¯ŸåŸŸåˆ†ç±»å‡†ç¡®ç‡å’Œæ£€æµ‹æ€§èƒ½"),
        ("è¯„ä¼°ç»“æœ", "åœ¨é›¨å¤©æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½"),
        ("è°ƒä¼˜å‚æ•°", "æ ¹æ®ç»“æœè°ƒæ•´åŸŸé€‚åº”å‚æ•°")
    ]
    
    for i, (title, desc) in enumerate(steps, 1):
        print(f"\n{i}. {title}")
        print(f"   {desc}")
    
    print("\nğŸ¯ ç›®æ ‡: æ˜¾è‘—æå‡æ¨¡å‹åœ¨é›¨å¤©æ¡ä»¶ä¸‹çš„æ£€æµ‹æ€§èƒ½!")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ MFDAM (Multi-scale Fusion Domain Adaptation Module)")
    print("Dayâ†’RainåŸŸé€‚åº”å¿«é€Ÿå…¥é—¨æ•™ç¨‹")
    print("ä¸“ä¸ºYOLOv8è®¾è®¡çš„åŸŸé€‚åº”è§£å†³æ–¹æ¡ˆ")
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        return
    
    # æ¼”ç¤ºæ ¸å¿ƒåŠŸèƒ½
    if not demonstrate_core_features():
        print("âŒ æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶
    config_dir = create_sample_configs()
    
    # æ˜¾ç¤ºè®­ç»ƒå‘½ä»¤
    show_training_commands(config_dir)
    
    # æ˜¾ç¤ºæ•°æ®é›†å‡†å¤‡æŒ‡å—
    show_dataset_preparation()
    
    # æ˜¾ç¤ºåç»­æ­¥éª¤
    show_next_steps()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ MFDAMå¿«é€Ÿå…¥é—¨æ•™ç¨‹å®Œæˆ!")
    print("ğŸš€ å‡†å¤‡å¥½å¼€å§‹ä½ çš„Dayâ†’RainåŸŸé€‚åº”ä¹‹æ—…äº†å—?")
    print("=" * 60)
    
    # æ˜¾ç¤ºæœ‰ç”¨çš„é“¾æ¥
    print("\nğŸ“š æ›´å¤šèµ„æº:")
    print("  â€¢ è¯¦ç»†æ–‡æ¡£: mfda/README_CN.md")
    print("  â€¢ ä½¿ç”¨ç¤ºä¾‹: example_mfdam_usage.py")
    print("  â€¢ é…ç½®æ–‡ä»¶: cfg/datasets/mfda/ å’Œ cfg/models/mfda/")
    print("  â€¢ é—®é¢˜åé¦ˆ: æäº¤GitHub Issue")

if __name__ == "__main__":
    main()